[INFO|tokenization_utils_base.py:2084] 2024-04-07 21:32:32,107 >> loading file tokenizer.model from cache at /home/wenning1/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-hf/snapshots/8a0442e81540efaeb1a0fe3e95477b5e0edfd423/tokenizer.model
[INFO|tokenization_utils_base.py:2084] 2024-04-07 21:32:32,107 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:2084] 2024-04-07 21:32:32,107 >> loading file special_tokens_map.json from cache at /home/wenning1/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-hf/snapshots/8a0442e81540efaeb1a0fe3e95477b5e0edfd423/special_tokens_map.json
[INFO|tokenization_utils_base.py:2084] 2024-04-07 21:32:32,107 >> loading file tokenizer_config.json from cache at /home/wenning1/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-hf/snapshots/8a0442e81540efaeb1a0fe3e95477b5e0edfd423/tokenizer_config.json
[INFO|tokenization_utils_base.py:2084] 2024-04-07 21:32:32,107 >> loading file tokenizer.json from cache at /home/wenning1/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-hf/snapshots/8a0442e81540efaeb1a0fe3e95477b5e0edfd423/tokenizer.json
Converting format of dataset (num_proc=16):   0%|          | 0/1000 [00:00<?, ? examples/s]Converting format of dataset (num_proc=16):   6%|▋         | 63/1000 [00:00<00:01, 601.37 examples/s]Converting format of dataset (num_proc=16): 100%|██████████| 1000/1000 [00:00<00:00, 3784.95 examples/s]
Running tokenizer on dataset (num_proc=16):   0%|          | 0/1000 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   6%|▋         | 63/1000 [00:00<00:06, 136.38 examples/s]Running tokenizer on dataset (num_proc=16):  19%|█▉        | 189/1000 [00:00<00:02, 371.79 examples/s]Running tokenizer on dataset (num_proc=16):  75%|███████▌  | 752/1000 [00:00<00:00, 1622.38 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 1000/1000 [00:00<00:00, 1251.89 examples/s]
[INFO|configuration_utils.py:726] 2024-04-07 21:32:34,806 >> loading configuration file config.json from cache at /home/wenning1/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-hf/snapshots/8a0442e81540efaeb1a0fe3e95477b5e0edfd423/config.json
[INFO|configuration_utils.py:789] 2024-04-07 21:32:34,808 >> Model config LlamaConfig {
  "_name_or_path": "meta-llama/Llama-2-7b-hf",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_position_embeddings": 4096,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "float16",
  "transformers_version": "4.39.3",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|modeling_utils.py:3283] 2024-04-07 21:32:34,836 >> loading weights file model.safetensors from cache at /home/wenning1/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-hf/snapshots/8a0442e81540efaeb1a0fe3e95477b5e0edfd423/model.safetensors.index.json
[INFO|modeling_utils.py:1417] 2024-04-07 21:32:34,837 >> Instantiating LlamaForCausalLM model under default dtype torch.float16.
[INFO|configuration_utils.py:928] 2024-04-07 21:32:34,838 >> Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": 2
}

Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:15<00:15, 15.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  7.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  8.59s/it]
[INFO|modeling_utils.py:4024] 2024-04-07 21:32:52,258 >> All model checkpoint weights were used when initializing LlamaForCausalLM.

[INFO|modeling_utils.py:4032] 2024-04-07 21:32:52,258 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at meta-llama/Llama-2-7b-hf.
If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.
[INFO|configuration_utils.py:883] 2024-04-07 21:32:52,525 >> loading configuration file generation_config.json from cache at /home/wenning1/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-hf/snapshots/8a0442e81540efaeb1a0fe3e95477b5e0edfd423/generation_config.json
[INFO|configuration_utils.py:928] 2024-04-07 21:32:52,526 >> Generate config GenerationConfig {
  "bos_token_id": 1,
  "do_sample": true,
  "eos_token_id": 2,
  "max_length": 4096,
  "pad_token_id": 0,
  "temperature": 0.6,
  "top_p": 0.9
}

/home/wenning1/.local/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:607] 2024-04-07 21:32:52,780 >> Using auto half precision backend
[INFO|trainer.py:1969] 2024-04-07 21:32:52,990 >> ***** Running training *****
[INFO|trainer.py:1970] 2024-04-07 21:32:52,990 >>   Num examples = 900
[INFO|trainer.py:1971] 2024-04-07 21:32:52,990 >>   Num Epochs = 3
[INFO|trainer.py:1972] 2024-04-07 21:32:52,990 >>   Instantaneous batch size per device = 1
[INFO|trainer.py:1975] 2024-04-07 21:32:52,990 >>   Total train batch size (w. parallel, distributed & accumulation) = 8
[INFO|trainer.py:1976] 2024-04-07 21:32:52,990 >>   Gradient Accumulation steps = 8
[INFO|trainer.py:1977] 2024-04-07 21:32:52,990 >>   Total optimization steps = 336
[INFO|trainer.py:1978] 2024-04-07 21:32:52,991 >>   Number of trainable parameters = 4,194,304
  0%|          | 0/336 [00:00<?, ?it/s]  0%|          | 1/336 [00:08<46:52,  8.39s/it]  1%|          | 2/336 [00:12<32:08,  5.77s/it]  1%|          | 3/336 [00:16<27:09,  4.89s/it]  1%|          | 4/336 [00:19<24:22,  4.41s/it]  1%|▏         | 5/336 [00:23<22:51,  4.14s/it]  2%|▏         | 6/336 [00:27<22:02,  4.01s/it]  2%|▏         | 7/336 [00:30<21:22,  3.90s/it]  2%|▏         | 8/336 [00:34<20:55,  3.83s/it]  3%|▎         | 9/336 [00:38<20:36,  3.78s/it]  3%|▎         | 10/336 [00:41<20:23,  3.75s/it]                                                  3%|▎         | 10/336 [00:41<20:23,  3.75s/it]  3%|▎         | 11/336 [00:45<20:14,  3.74s/it]  4%|▎         | 12/336 [00:49<20:00,  3.71s/it]  4%|▍         | 13/336 [00:53<20:06,  3.74s/it]  4%|▍         | 14/336 [00:56<19:57,  3.72s/it]  4%|▍         | 15/336 [01:00<19:59,  3.74s/it]  5%|▍         | 16/336 [01:04<20:03,  3.76s/it]  5%|▌         | 17/336 [01:08<19:49,  3.73s/it]  5%|▌         | 18/336 [01:12<20:10,  3.81s/it]  6%|▌         | 19/336 [01:15<19:57,  3.78s/it]  6%|▌         | 20/336 [01:19<19:44,  3.75s/it]                                                  6%|▌         | 20/336 [01:19<19:44,  3.75s/it]  6%|▋         | 21/336 [01:23<19:35,  3.73s/it]  7%|▋         | 22/336 [01:26<19:35,  3.74s/it]  7%|▋         | 23/336 [01:30<20:00,  3.83s/it]  7%|▋         | 24/336 [01:34<19:33,  3.76s/it]  7%|▋         | 25/336 [01:38<19:39,  3.79s/it]  8%|▊         | 26/336 [01:42<19:35,  3.79s/it]  8%|▊         | 27/336 [01:45<19:22,  3.76s/it]  8%|▊         | 28/336 [01:49<19:10,  3.73s/it]  9%|▊         | 29/336 [01:53<19:15,  3.77s/it]  9%|▉         | 30/336 [01:57<19:09,  3.76s/it]                                                  9%|▉         | 30/336 [01:57<19:09,  3.76s/it]  9%|▉         | 31/336 [02:00<18:57,  3.73s/it] 10%|▉         | 32/336 [02:04<18:51,  3.72s/it] 10%|▉         | 33/336 [02:08<18:36,  3.69s/it] 10%|█         | 34/336 [02:11<18:50,  3.74s/it] 10%|█         | 35/336 [02:15<19:00,  3.79s/it] 11%|█         | 36/336 [02:19<18:45,  3.75s/it] 11%|█         | 37/336 [02:23<18:32,  3.72s/it] 11%|█▏        | 38/336 [02:27<18:52,  3.80s/it] 12%|█▏        | 39/336 [02:31<19:13,  3.88s/it] 12%|█▏        | 40/336 [02:35<19:17,  3.91s/it]                                                 12%|█▏        | 40/336 [02:35<19:17,  3.91s/it] 12%|█▏        | 41/336 [02:39<19:05,  3.88s/it] 12%|█▎        | 42/336 [02:42<18:58,  3.87s/it] 13%|█▎        | 43/336 [02:46<18:56,  3.88s/it] 13%|█▎        | 44/336 [02:50<18:43,  3.85s/it] 13%|█▎        | 45/336 [02:54<18:18,  3.77s/it] 14%|█▎        | 46/336 [02:57<18:02,  3.73s/it] 14%|█▍        | 47/336 [03:01<17:56,  3.72s/it] 14%|█▍        | 48/336 [03:05<17:54,  3.73s/it] 15%|█▍        | 49/336 [03:08<17:47,  3.72s/it] 15%|█▍        | 50/336 [03:12<17:48,  3.74s/it]                                                 15%|█▍        | 50/336 [03:12<17:48,  3.74s/it] 15%|█▌        | 51/336 [03:16<17:58,  3.78s/it] 15%|█▌        | 52/336 [03:20<18:15,  3.86s/it] 16%|█▌        | 53/336 [03:24<17:58,  3.81s/it] 16%|█▌        | 54/336 [03:28<17:57,  3.82s/it] 16%|█▋        | 55/336 [03:31<17:38,  3.77s/it] 17%|█▋        | 56/336 [03:35<17:26,  3.74s/it] 17%|█▋        | 57/336 [03:39<17:21,  3.73s/it] 17%|█▋        | 58/336 [03:42<17:04,  3.69s/it] 18%|█▊        | 59/336 [03:46<17:10,  3.72s/it] 18%|█▊        | 60/336 [03:50<17:06,  3.72s/it]                                                 18%|█▊        | 60/336 [03:50<17:06,  3.72s/it] 18%|█▊        | 61/336 [03:53<16:54,  3.69s/it] 18%|█▊        | 62/336 [03:57<17:02,  3.73s/it] 19%|█▉        | 63/336 [04:01<17:01,  3.74s/it] 19%|█▉        | 64/336 [04:05<17:06,  3.77s/it] 19%|█▉        | 65/336 [04:09<17:02,  3.77s/it] 20%|█▉        | 66/336 [04:12<16:51,  3.75s/it] 20%|█▉        | 67/336 [04:16<16:43,  3.73s/it] 20%|██        | 68/336 [04:20<16:49,  3.77s/it] 21%|██        | 69/336 [04:24<16:43,  3.76s/it] 21%|██        | 70/336 [04:27<16:48,  3.79s/it]                                                 21%|██        | 70/336 [04:27<16:48,  3.79s/it] 21%|██        | 71/336 [04:31<16:34,  3.75s/it] 21%|██▏       | 72/336 [04:35<16:09,  3.67s/it] 22%|██▏       | 73/336 [04:38<16:07,  3.68s/it] 22%|██▏       | 74/336 [04:42<16:04,  3.68s/it] 22%|██▏       | 75/336 [04:46<16:08,  3.71s/it] 23%|██▎       | 76/336 [04:49<16:03,  3.71s/it] 23%|██▎       | 77/336 [04:53<15:56,  3.69s/it] 23%|██▎       | 78/336 [04:57<15:49,  3.68s/it] 24%|██▎       | 79/336 [05:01<15:58,  3.73s/it] 24%|██▍       | 80/336 [05:05<16:11,  3.79s/it]                                                 24%|██▍       | 80/336 [05:05<16:11,  3.79s/it] 24%|██▍       | 81/336 [05:08<15:59,  3.76s/it] 24%|██▍       | 82/336 [05:12<15:55,  3.76s/it] 25%|██▍       | 83/336 [05:16<15:38,  3.71s/it] 25%|██▌       | 84/336 [05:19<15:29,  3.69s/it] 25%|██▌       | 85/336 [05:23<15:26,  3.69s/it] 26%|██▌       | 86/336 [05:27<15:18,  3.68s/it] 26%|██▌       | 87/336 [05:30<15:17,  3.68s/it] 26%|██▌       | 88/336 [05:34<15:37,  3.78s/it] 26%|██▋       | 89/336 [05:38<15:35,  3.79s/it] 27%|██▋       | 90/336 [05:42<15:33,  3.79s/it]                                                 27%|██▋       | 90/336 [05:42<15:33,  3.79s/it] 27%|██▋       | 91/336 [05:46<15:27,  3.79s/it] 27%|██▋       | 92/336 [05:50<15:48,  3.89s/it] 28%|██▊       | 93/336 [05:53<15:26,  3.81s/it] 28%|██▊       | 94/336 [05:57<15:15,  3.78s/it] 28%|██▊       | 95/336 [06:01<15:15,  3.80s/it] 29%|██▊       | 96/336 [06:05<15:13,  3.81s/it] 29%|██▉       | 97/336 [06:09<15:11,  3.81s/it] 29%|██▉       | 98/336 [06:13<15:12,  3.84s/it] 29%|██▉       | 99/336 [06:16<15:01,  3.80s/it] 30%|██▉       | 100/336 [06:20<15:03,  3.83s/it]                                                  30%|██▉       | 100/336 [06:20<15:03,  3.83s/it][INFO|trainer.py:3512] 2024-04-07 21:39:13,635 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-04-07 21:39:13,636 >>   Num examples = 100
[INFO|trainer.py:3517] 2024-04-07 21:39:13,636 >>   Batch size = 1

  0%|          | 0/100 [00:00<?, ?it/s][A
  2%|▏         | 2/100 [00:00<00:10,  9.42it/s][A
  3%|▎         | 3/100 [00:00<00:14,  6.84it/s][A
  4%|▍         | 4/100 [00:00<00:17,  5.50it/s][A
  5%|▌         | 5/100 [00:00<00:18,  5.23it/s][A
  6%|▌         | 6/100 [00:01<00:18,  5.04it/s][A
  7%|▋         | 7/100 [00:01<00:18,  4.96it/s][A
  8%|▊         | 8/100 [00:01<00:18,  4.92it/s][A
  9%|▉         | 9/100 [00:01<00:18,  4.97it/s][A
 10%|█         | 10/100 [00:01<00:18,  4.88it/s][A
 11%|█         | 11/100 [00:02<00:18,  4.91it/s][A
 12%|█▏        | 12/100 [00:02<00:19,  4.52it/s][A
 13%|█▎        | 13/100 [00:02<00:18,  4.61it/s][A
 14%|█▍        | 14/100 [00:02<00:18,  4.69it/s][A
 15%|█▌        | 15/100 [00:02<00:18,  4.71it/s][A
 16%|█▌        | 16/100 [00:03<00:17,  4.73it/s][A
 17%|█▋        | 17/100 [00:03<00:17,  4.75it/s][A
 18%|█▊        | 18/100 [00:03<00:17,  4.77it/s][A
 19%|█▉        | 19/100 [00:03<00:16,  4.86it/s][A
 20%|██        | 20/100 [00:04<00:16,  4.94it/s][A
 21%|██        | 21/100 [00:04<00:16,  4.82it/s][A
 22%|██▏       | 22/100 [00:04<00:16,  4.86it/s][A
 23%|██▎       | 23/100 [00:04<00:15,  4.85it/s][A
 24%|██▍       | 24/100 [00:04<00:15,  4.94it/s][A
 25%|██▌       | 25/100 [00:05<00:15,  4.90it/s][A
 26%|██▌       | 26/100 [00:05<00:14,  4.95it/s][A
 27%|██▋       | 27/100 [00:05<00:15,  4.86it/s][A
 28%|██▊       | 28/100 [00:05<00:14,  4.90it/s][A
 29%|██▉       | 29/100 [00:05<00:14,  4.80it/s][A
 30%|███       | 30/100 [00:06<00:14,  4.84it/s][A
 31%|███       | 31/100 [00:06<00:14,  4.82it/s][A
 32%|███▏      | 32/100 [00:06<00:14,  4.79it/s][A
 33%|███▎      | 33/100 [00:06<00:14,  4.51it/s][A
 34%|███▍      | 34/100 [00:06<00:14,  4.64it/s][A
 35%|███▌      | 35/100 [00:07<00:13,  4.69it/s][A
 36%|███▌      | 36/100 [00:07<00:14,  4.45it/s][A
 37%|███▋      | 37/100 [00:07<00:13,  4.56it/s][A
 38%|███▊      | 38/100 [00:07<00:13,  4.61it/s][A
 39%|███▉      | 39/100 [00:08<00:12,  4.70it/s][A
 40%|████      | 40/100 [00:08<00:12,  4.80it/s][A
 41%|████      | 41/100 [00:08<00:12,  4.80it/s][A
 42%|████▏     | 42/100 [00:08<00:12,  4.79it/s][A
 43%|████▎     | 43/100 [00:08<00:11,  4.77it/s][A
 44%|████▍     | 44/100 [00:09<00:11,  4.76it/s][A
 45%|████▌     | 45/100 [00:09<00:11,  4.76it/s][A
 46%|████▌     | 46/100 [00:09<00:11,  4.81it/s][A
 47%|████▋     | 47/100 [00:09<00:11,  4.75it/s][A
 48%|████▊     | 48/100 [00:09<00:10,  4.79it/s][A
 49%|████▉     | 49/100 [00:10<00:10,  4.79it/s][A
 50%|█████     | 50/100 [00:10<00:10,  4.73it/s][A
 51%|█████     | 51/100 [00:10<00:10,  4.77it/s][A
 52%|█████▏    | 52/100 [00:10<00:10,  4.74it/s][A
 53%|█████▎    | 53/100 [00:10<00:10,  4.70it/s][A
 54%|█████▍    | 54/100 [00:11<00:09,  4.78it/s][A
 55%|█████▌    | 55/100 [00:11<00:09,  4.78it/s][A
 56%|█████▌    | 56/100 [00:11<00:09,  4.80it/s][A
 57%|█████▋    | 57/100 [00:11<00:08,  4.87it/s][A
 58%|█████▊    | 58/100 [00:11<00:08,  4.82it/s][A
 59%|█████▉    | 59/100 [00:12<00:08,  4.81it/s][A
 60%|██████    | 60/100 [00:12<00:08,  4.80it/s][A
 61%|██████    | 61/100 [00:12<00:08,  4.81it/s][A
 62%|██████▏   | 62/100 [00:12<00:07,  4.82it/s][A
 63%|██████▎   | 63/100 [00:13<00:07,  4.84it/s][A
 64%|██████▍   | 64/100 [00:13<00:07,  4.78it/s][A
 65%|██████▌   | 65/100 [00:13<00:07,  4.83it/s][A
 66%|██████▌   | 66/100 [00:13<00:07,  4.52it/s][A
 67%|██████▋   | 67/100 [00:13<00:07,  4.59it/s][A
 68%|██████▊   | 68/100 [00:14<00:06,  4.70it/s][A
 69%|██████▉   | 69/100 [00:14<00:06,  4.74it/s][A
 70%|███████   | 70/100 [00:14<00:06,  4.72it/s][A
 71%|███████   | 71/100 [00:14<00:06,  4.67it/s][A
 72%|███████▏  | 72/100 [00:14<00:05,  4.71it/s][A
 73%|███████▎  | 73/100 [00:15<00:06,  4.45it/s][A
 74%|███████▍  | 74/100 [00:15<00:05,  4.55it/s][A
 75%|███████▌  | 75/100 [00:15<00:05,  4.66it/s][A
 76%|███████▌  | 76/100 [00:15<00:05,  4.72it/s][A
 77%|███████▋  | 77/100 [00:16<00:04,  4.77it/s][A
 78%|███████▊  | 78/100 [00:16<00:04,  4.75it/s][A
 79%|███████▉  | 79/100 [00:16<00:04,  4.77it/s][A
 80%|████████  | 80/100 [00:16<00:04,  4.83it/s][A
 81%|████████  | 81/100 [00:16<00:03,  4.81it/s][A
 82%|████████▏ | 82/100 [00:17<00:03,  4.86it/s][A
 83%|████████▎ | 83/100 [00:17<00:03,  4.85it/s][A
 84%|████████▍ | 84/100 [00:17<00:03,  4.89it/s][A
 85%|████████▌ | 85/100 [00:17<00:03,  4.87it/s][A
 86%|████████▌ | 86/100 [00:17<00:02,  4.85it/s][A
 87%|████████▋ | 87/100 [00:18<00:02,  4.83it/s][A
 88%|████████▊ | 88/100 [00:18<00:02,  4.82it/s][A
 89%|████████▉ | 89/100 [00:18<00:02,  4.84it/s][A
 90%|█████████ | 90/100 [00:18<00:02,  4.81it/s][A
 91%|█████████ | 91/100 [00:18<00:01,  4.78it/s][A
 92%|█████████▏| 92/100 [00:19<00:01,  4.75it/s][A
 93%|█████████▎| 93/100 [00:19<00:01,  4.80it/s][A
 94%|█████████▍| 94/100 [00:19<00:01,  4.75it/s][A
 95%|█████████▌| 95/100 [00:19<00:01,  4.77it/s][A
 96%|█████████▌| 96/100 [00:19<00:00,  4.78it/s][A
 97%|█████████▋| 97/100 [00:20<00:00,  4.71it/s][A
 98%|█████████▊| 98/100 [00:20<00:00,  4.67it/s][A
 99%|█████████▉| 99/100 [00:20<00:00,  4.43it/s][A
100%|██████████| 100/100 [00:20<00:00,  4.29it/s][A                                                 
                                                 [A 30%|██▉       | 100/336 [06:41<15:03,  3.83s/it]
100%|██████████| 100/100 [00:20<00:00,  4.29it/s][A
                                                 [A[INFO|trainer.py:3203] 2024-04-07 21:39:34,769 >> Saving model checkpoint to ../../saves/LLaMA2-7B/lora/sft/checkpoint-100
[INFO|configuration_utils.py:726] 2024-04-07 21:39:35,315 >> loading configuration file config.json from cache at /home/wenning1/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-hf/snapshots/8a0442e81540efaeb1a0fe3e95477b5e0edfd423/config.json
[INFO|configuration_utils.py:789] 2024-04-07 21:39:35,316 >> Model config LlamaConfig {
  "_name_or_path": "meta-llama/Llama-2-7b-hf",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_position_embeddings": 4096,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "float16",
  "transformers_version": "4.39.3",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|tokenization_utils_base.py:2502] 2024-04-07 21:39:35,408 >> tokenizer config file saved in ../../saves/LLaMA2-7B/lora/sft/checkpoint-100/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-04-07 21:39:35,409 >> Special tokens file saved in ../../saves/LLaMA2-7B/lora/sft/checkpoint-100/special_tokens_map.json
 30%|███       | 101/336 [06:46<40:30, 10.34s/it] 30%|███       | 102/336 [06:49<32:40,  8.38s/it] 31%|███       | 103/336 [06:53<27:04,  6.97s/it] 31%|███       | 104/336 [06:57<23:12,  6.00s/it] 31%|███▏      | 105/336 [07:01<20:40,  5.37s/it] 32%|███▏      | 106/336 [07:05<18:57,  4.95s/it] 32%|███▏      | 107/336 [07:09<17:31,  4.59s/it] 32%|███▏      | 108/336 [07:12<16:25,  4.32s/it] 32%|███▏      | 109/336 [07:16<15:38,  4.14s/it] 33%|███▎      | 110/336 [07:20<15:04,  4.00s/it]                                                  33%|███▎      | 110/336 [07:20<15:04,  4.00s/it] 33%|███▎      | 111/336 [07:23<14:41,  3.92s/it] 33%|███▎      | 112/336 [07:27<14:26,  3.87s/it] 34%|███▎      | 113/336 [07:31<14:11,  3.82s/it] 34%|███▍      | 114/336 [07:35<14:02,  3.80s/it] 34%|███▍      | 115/336 [07:38<13:43,  3.73s/it] 35%|███▍      | 116/336 [07:42<13:45,  3.75s/it] 35%|███▍      | 117/336 [07:46<13:40,  3.75s/it] 35%|███▌      | 118/336 [07:49<13:41,  3.77s/it] 35%|███▌      | 119/336 [07:53<13:36,  3.76s/it] 36%|███▌      | 120/336 [07:57<13:42,  3.81s/it]                                                  36%|███▌      | 120/336 [07:57<13:42,  3.81s/it] 36%|███▌      | 121/336 [08:01<13:30,  3.77s/it] 36%|███▋      | 122/336 [08:05<13:34,  3.81s/it] 37%|███▋      | 123/336 [08:08<13:30,  3.81s/it] 37%|███▋      | 124/336 [08:12<13:26,  3.81s/it] 37%|███▋      | 125/336 [08:16<13:16,  3.78s/it] 38%|███▊      | 126/336 [08:20<13:15,  3.79s/it] 38%|███▊      | 127/336 [08:24<13:16,  3.81s/it] 38%|███▊      | 128/336 [08:28<13:15,  3.83s/it] 38%|███▊      | 129/336 [08:31<13:05,  3.80s/it] 39%|███▊      | 130/336 [08:35<13:03,  3.80s/it]                                                  39%|███▊      | 130/336 [08:35<13:03,  3.80s/it] 39%|███▉      | 131/336 [08:39<12:55,  3.78s/it] 39%|███▉      | 132/336 [08:42<12:42,  3.74s/it] 40%|███▉      | 133/336 [08:46<12:37,  3.73s/it] 40%|███▉      | 134/336 [08:50<12:44,  3.78s/it] 40%|████      | 135/336 [08:54<12:33,  3.75s/it] 40%|████      | 136/336 [08:58<12:35,  3.78s/it] 41%|████      | 137/336 [09:01<12:26,  3.75s/it] 41%|████      | 138/336 [09:05<12:17,  3.72s/it] 41%|████▏     | 139/336 [09:09<12:13,  3.72s/it] 42%|████▏     | 140/336 [09:12<12:05,  3.70s/it]                                                  42%|████▏     | 140/336 [09:12<12:05,  3.70s/it] 42%|████▏     | 141/336 [09:16<12:06,  3.72s/it] 42%|████▏     | 142/336 [09:20<11:59,  3.71s/it] 43%|████▎     | 143/336 [09:23<11:56,  3.71s/it] 43%|████▎     | 144/336 [09:27<11:54,  3.72s/it] 43%|████▎     | 145/336 [09:31<11:53,  3.74s/it] 43%|████▎     | 146/336 [09:35<11:52,  3.75s/it] 44%|████▍     | 147/336 [09:39<11:48,  3.75s/it] 44%|████▍     | 148/336 [09:42<11:48,  3.77s/it] 44%|████▍     | 149/336 [09:46<11:48,  3.79s/it] 45%|████▍     | 150/336 [09:50<11:44,  3.79s/it]                                                  45%|████▍     | 150/336 [09:50<11:44,  3.79s/it] 45%|████▍     | 151/336 [09:54<11:35,  3.76s/it] 45%|████▌     | 152/336 [09:57<11:34,  3.77s/it] 46%|████▌     | 153/336 [10:01<11:25,  3.75s/it] 46%|████▌     | 154/336 [10:05<11:21,  3.75s/it] 46%|████▌     | 155/336 [10:09<11:22,  3.77s/it] 46%|████▋     | 156/336 [10:12<11:17,  3.76s/it] 47%|████▋     | 157/336 [10:16<11:12,  3.76s/it] 47%|████▋     | 158/336 [10:20<11:06,  3.74s/it] 47%|████▋     | 159/336 [10:24<11:15,  3.82s/it] 48%|████▊     | 160/336 [10:28<11:08,  3.80s/it]                                                  48%|████▊     | 160/336 [10:28<11:08,  3.80s/it] 48%|████▊     | 161/336 [10:31<11:01,  3.78s/it] 48%|████▊     | 162/336 [10:35<10:55,  3.76s/it] 49%|████▊     | 163/336 [10:39<10:57,  3.80s/it] 49%|████▉     | 164/336 [10:43<10:57,  3.82s/it] 49%|████▉     | 165/336 [10:47<10:51,  3.81s/it] 49%|████▉     | 166/336 [10:50<10:43,  3.79s/it] 50%|████▉     | 167/336 [10:54<10:31,  3.73s/it] 50%|█████     | 168/336 [10:58<10:26,  3.73s/it] 50%|█████     | 169/336 [11:01<10:21,  3.72s/it] 51%|█████     | 170/336 [11:05<10:12,  3.69s/it]                                                  51%|█████     | 170/336 [11:05<10:12,  3.69s/it] 51%|█████     | 171/336 [11:09<10:09,  3.69s/it] 51%|█████     | 172/336 [11:13<10:17,  3.77s/it] 51%|█████▏    | 173/336 [11:16<10:12,  3.76s/it] 52%|█████▏    | 174/336 [11:20<10:13,  3.79s/it] 52%|█████▏    | 175/336 [11:24<10:00,  3.73s/it] 52%|█████▏    | 176/336 [11:28<10:01,  3.76s/it] 53%|█████▎    | 177/336 [11:32<09:59,  3.77s/it] 53%|█████▎    | 178/336 [11:35<10:03,  3.82s/it] 53%|█████▎    | 179/336 [11:39<09:59,  3.82s/it] 54%|█████▎    | 180/336 [11:43<09:50,  3.78s/it]                                                  54%|█████▎    | 180/336 [11:43<09:50,  3.78s/it] 54%|█████▍    | 181/336 [11:47<09:41,  3.75s/it] 54%|█████▍    | 182/336 [11:50<09:41,  3.78s/it] 54%|█████▍    | 183/336 [11:54<09:33,  3.75s/it] 55%|█████▍    | 184/336 [11:58<09:33,  3.77s/it] 55%|█████▌    | 185/336 [12:02<09:27,  3.76s/it] 55%|█████▌    | 186/336 [12:06<09:32,  3.82s/it] 56%|█████▌    | 187/336 [12:09<09:24,  3.79s/it] 56%|█████▌    | 188/336 [12:13<09:16,  3.76s/it] 56%|█████▋    | 189/336 [12:17<09:07,  3.72s/it] 57%|█████▋    | 190/336 [12:21<09:07,  3.75s/it]                                                  57%|█████▋    | 190/336 [12:21<09:07,  3.75s/it] 57%|█████▋    | 191/336 [12:24<09:02,  3.74s/it] 57%|█████▋    | 192/336 [12:28<08:54,  3.71s/it] 57%|█████▋    | 193/336 [12:32<08:50,  3.71s/it] 58%|█████▊    | 194/336 [12:35<08:48,  3.72s/it] 58%|█████▊    | 195/336 [12:39<08:39,  3.69s/it] 58%|█████▊    | 196/336 [12:43<08:43,  3.74s/it] 59%|█████▊    | 197/336 [12:47<08:40,  3.74s/it] 59%|█████▉    | 198/336 [12:51<08:51,  3.85s/it] 59%|█████▉    | 199/336 [12:54<08:44,  3.83s/it] 60%|█████▉    | 200/336 [12:58<08:34,  3.79s/it]                                                  60%|█████▉    | 200/336 [12:58<08:34,  3.79s/it][INFO|trainer.py:3512] 2024-04-07 21:45:51,616 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-04-07 21:45:51,616 >>   Num examples = 100
[INFO|trainer.py:3517] 2024-04-07 21:45:51,616 >>   Batch size = 1

  0%|          | 0/100 [00:00<?, ?it/s][A
  2%|▏         | 2/100 [00:00<00:10,  9.44it/s][A
  3%|▎         | 3/100 [00:00<00:14,  6.80it/s][A
  4%|▍         | 4/100 [00:00<00:16,  5.78it/s][A
  5%|▌         | 5/100 [00:00<00:17,  5.36it/s][A
  6%|▌         | 6/100 [00:01<00:18,  5.17it/s][A
  7%|▋         | 7/100 [00:01<00:18,  5.05it/s][A
  8%|▊         | 8/100 [00:01<00:18,  4.96it/s][A
  9%|▉         | 9/100 [00:01<00:18,  4.97it/s][A
 10%|█         | 10/100 [00:01<00:18,  4.96it/s][A
 11%|█         | 11/100 [00:02<00:17,  4.96it/s][A
 12%|█▏        | 12/100 [00:02<00:19,  4.63it/s][A
 13%|█▎        | 13/100 [00:02<00:18,  4.69it/s][A
 14%|█▍        | 14/100 [00:02<00:18,  4.74it/s][A
 15%|█▌        | 15/100 [00:02<00:17,  4.72it/s][A
 16%|█▌        | 16/100 [00:03<00:17,  4.74it/s][A
 17%|█▋        | 17/100 [00:03<00:17,  4.74it/s][A
 18%|█▊        | 18/100 [00:03<00:17,  4.73it/s][A
 19%|█▉        | 19/100 [00:03<00:16,  4.82it/s][A
 20%|██        | 20/100 [00:03<00:16,  4.90it/s][A
 21%|██        | 21/100 [00:04<00:16,  4.85it/s][A
 22%|██▏       | 22/100 [00:04<00:15,  4.88it/s][A
 23%|██▎       | 23/100 [00:04<00:15,  4.85it/s][A
 24%|██▍       | 24/100 [00:04<00:15,  4.87it/s][A
 25%|██▌       | 25/100 [00:05<00:15,  4.83it/s][A
 26%|██▌       | 26/100 [00:05<00:14,  4.93it/s][A
 27%|██▋       | 27/100 [00:05<00:14,  4.87it/s][A
 28%|██▊       | 28/100 [00:05<00:14,  4.92it/s][A
 29%|██▉       | 29/100 [00:05<00:14,  4.80it/s][A
 30%|███       | 30/100 [00:06<00:14,  4.85it/s][A
 31%|███       | 31/100 [00:06<00:14,  4.80it/s][A
 32%|███▏      | 32/100 [00:06<00:14,  4.77it/s][A
 33%|███▎      | 33/100 [00:06<00:14,  4.48it/s][A
 34%|███▍      | 34/100 [00:06<00:14,  4.58it/s][A
 35%|███▌      | 35/100 [00:07<00:14,  4.62it/s][A
 36%|███▌      | 36/100 [00:07<00:14,  4.36it/s][A
 37%|███▋      | 37/100 [00:07<00:14,  4.47it/s][A
 38%|███▊      | 38/100 [00:07<00:13,  4.53it/s][A
 39%|███▉      | 39/100 [00:08<00:13,  4.57it/s][A
 40%|████      | 40/100 [00:08<00:12,  4.67it/s][A
 41%|████      | 41/100 [00:08<00:12,  4.77it/s][A
 42%|████▏     | 42/100 [00:08<00:12,  4.74it/s][A
 43%|████▎     | 43/100 [00:08<00:11,  4.79it/s][A
 44%|████▍     | 44/100 [00:09<00:12,  4.59it/s][A
 45%|████▌     | 45/100 [00:09<00:11,  4.69it/s][A
 46%|████▌     | 46/100 [00:09<00:11,  4.79it/s][A
 47%|████▋     | 47/100 [00:09<00:11,  4.81it/s][A
 48%|████▊     | 48/100 [00:09<00:10,  4.81it/s][A
 49%|████▉     | 49/100 [00:10<00:10,  4.82it/s][A
 50%|█████     | 50/100 [00:10<00:10,  4.85it/s][A
 51%|█████     | 51/100 [00:10<00:10,  4.88it/s][A
 52%|█████▏    | 52/100 [00:10<00:09,  4.84it/s][A
 53%|█████▎    | 53/100 [00:10<00:09,  4.84it/s][A
 54%|█████▍    | 54/100 [00:11<00:09,  4.89it/s][A
 55%|█████▌    | 55/100 [00:11<00:09,  4.89it/s][A
 56%|█████▌    | 56/100 [00:11<00:09,  4.88it/s][A
 57%|█████▋    | 57/100 [00:11<00:08,  4.85it/s][A
 58%|█████▊    | 58/100 [00:11<00:08,  4.86it/s][A
 59%|█████▉    | 59/100 [00:12<00:08,  4.83it/s][A
 60%|██████    | 60/100 [00:12<00:08,  4.79it/s][A
 61%|██████    | 61/100 [00:12<00:08,  4.78it/s][A
 62%|██████▏   | 62/100 [00:12<00:07,  4.80it/s][A
 63%|██████▎   | 63/100 [00:13<00:07,  4.82it/s][A
 64%|██████▍   | 64/100 [00:13<00:07,  4.87it/s][A
 65%|██████▌   | 65/100 [00:13<00:07,  4.85it/s][A
 66%|██████▌   | 66/100 [00:13<00:07,  4.54it/s][A
 67%|██████▋   | 67/100 [00:13<00:07,  4.62it/s][A
 68%|██████▊   | 68/100 [00:14<00:06,  4.69it/s][A
 69%|██████▉   | 69/100 [00:14<00:06,  4.72it/s][A
 70%|███████   | 70/100 [00:14<00:06,  4.73it/s][A
 71%|███████   | 71/100 [00:14<00:06,  4.72it/s][A
 72%|███████▏  | 72/100 [00:14<00:05,  4.67it/s][A
 73%|███████▎  | 73/100 [00:15<00:06,  4.46it/s][A
 74%|███████▍  | 74/100 [00:15<00:05,  4.58it/s][A
 75%|███████▌  | 75/100 [00:15<00:05,  4.69it/s][A
 76%|███████▌  | 76/100 [00:15<00:05,  4.77it/s][A
 77%|███████▋  | 77/100 [00:15<00:04,  4.78it/s][A
 78%|███████▊  | 78/100 [00:16<00:04,  4.80it/s][A
 79%|███████▉  | 79/100 [00:16<00:04,  4.80it/s][A
 80%|████████  | 80/100 [00:16<00:04,  4.82it/s][A
 81%|████████  | 81/100 [00:16<00:04,  4.73it/s][A
 82%|████████▏ | 82/100 [00:17<00:03,  4.82it/s][A
 83%|████████▎ | 83/100 [00:17<00:03,  4.76it/s][A
 84%|████████▍ | 84/100 [00:17<00:03,  4.80it/s][A
 85%|████████▌ | 85/100 [00:17<00:03,  4.80it/s][A
 86%|████████▌ | 86/100 [00:17<00:02,  4.81it/s][A
 87%|████████▋ | 87/100 [00:18<00:02,  4.78it/s][A
 88%|████████▊ | 88/100 [00:18<00:02,  4.69it/s][A
 89%|████████▉ | 89/100 [00:18<00:02,  4.75it/s][A
 90%|█████████ | 90/100 [00:18<00:02,  4.77it/s][A
 91%|█████████ | 91/100 [00:18<00:01,  4.82it/s][A
 92%|█████████▏| 92/100 [00:19<00:01,  4.75it/s][A
 93%|█████████▎| 93/100 [00:19<00:01,  4.83it/s][A
 94%|█████████▍| 94/100 [00:19<00:01,  4.83it/s][A
 95%|█████████▌| 95/100 [00:19<00:01,  4.87it/s][A
 96%|█████████▌| 96/100 [00:19<00:00,  4.82it/s][A
 97%|█████████▋| 97/100 [00:20<00:00,  4.81it/s][A
 98%|█████████▊| 98/100 [00:20<00:00,  4.80it/s][A
 99%|█████████▉| 99/100 [00:20<00:00,  4.51it/s][A
100%|██████████| 100/100 [00:20<00:00,  4.32it/s][A                                                 
                                                 [A 60%|█████▉    | 200/336 [13:19<08:34,  3.79s/it]
100%|██████████| 100/100 [00:20<00:00,  4.32it/s][A
                                                 [A[INFO|trainer.py:3203] 2024-04-07 21:46:12,711 >> Saving model checkpoint to ../../saves/LLaMA2-7B/lora/sft/checkpoint-200
[INFO|configuration_utils.py:726] 2024-04-07 21:46:13,824 >> loading configuration file config.json from cache at /home/wenning1/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-hf/snapshots/8a0442e81540efaeb1a0fe3e95477b5e0edfd423/config.json
[INFO|configuration_utils.py:789] 2024-04-07 21:46:13,826 >> Model config LlamaConfig {
  "_name_or_path": "meta-llama/Llama-2-7b-hf",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_position_embeddings": 4096,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "float16",
  "transformers_version": "4.39.3",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|tokenization_utils_base.py:2502] 2024-04-07 21:46:13,924 >> tokenizer config file saved in ../../saves/LLaMA2-7B/lora/sft/checkpoint-200/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-04-07 21:46:13,924 >> Special tokens file saved in ../../saves/LLaMA2-7B/lora/sft/checkpoint-200/special_tokens_map.json
 60%|█████▉    | 201/336 [13:24<23:35, 10.49s/it] 60%|██████    | 202/336 [13:28<18:58,  8.50s/it] 60%|██████    | 203/336 [13:32<15:36,  7.04s/it] 61%|██████    | 204/336 [13:35<13:15,  6.03s/it] 61%|██████    | 205/336 [13:39<11:39,  5.34s/it] 61%|██████▏   | 206/336 [13:43<10:26,  4.82s/it] 62%|██████▏   | 207/336 [13:46<09:37,  4.47s/it] 62%|██████▏   | 208/336 [13:50<08:59,  4.22s/it] 62%|██████▏   | 209/336 [13:54<08:46,  4.15s/it] 62%|██████▎   | 210/336 [13:58<08:26,  4.02s/it]                                                  62%|██████▎   | 210/336 [13:58<08:26,  4.02s/it] 63%|██████▎   | 211/336 [14:02<08:13,  3.95s/it] 63%|██████▎   | 212/336 [14:05<08:00,  3.87s/it] 63%|██████▎   | 213/336 [14:09<07:57,  3.88s/it] 64%|██████▎   | 214/336 [14:13<07:52,  3.87s/it] 64%|██████▍   | 215/336 [14:17<07:45,  3.85s/it] 64%|██████▍   | 216/336 [14:20<07:35,  3.80s/it] 65%|██████▍   | 217/336 [14:24<07:31,  3.80s/it] 65%|██████▍   | 218/336 [14:28<07:22,  3.75s/it] 65%|██████▌   | 219/336 [14:32<07:19,  3.76s/it] 65%|██████▌   | 220/336 [14:36<07:18,  3.78s/it]                                                  65%|██████▌   | 220/336 [14:36<07:18,  3.78s/it] 66%|██████▌   | 221/336 [14:39<07:13,  3.77s/it] 66%|██████▌   | 222/336 [14:43<07:13,  3.80s/it] 66%|██████▋   | 223/336 [14:47<07:05,  3.76s/it] 67%|██████▋   | 224/336 [14:50<06:59,  3.74s/it] 67%|██████▋   | 225/336 [14:54<06:57,  3.76s/it] 67%|██████▋   | 226/336 [14:58<06:51,  3.74s/it] 68%|██████▊   | 227/336 [15:02<06:52,  3.78s/it] 68%|██████▊   | 228/336 [15:06<06:50,  3.80s/it] 68%|██████▊   | 229/336 [15:10<06:50,  3.84s/it] 68%|██████▊   | 230/336 [15:13<06:44,  3.81s/it]                                                  68%|██████▊   | 230/336 [15:13<06:44,  3.81s/it] 69%|██████▉   | 231/336 [15:17<06:41,  3.83s/it] 69%|██████▉   | 232/336 [15:21<06:35,  3.80s/it] 69%|██████▉   | 233/336 [15:25<06:28,  3.77s/it] 70%|██████▉   | 234/336 [15:28<06:24,  3.77s/it] 70%|██████▉   | 235/336 [15:32<06:22,  3.79s/it] 70%|███████   | 236/336 [15:36<06:17,  3.77s/it] 71%|███████   | 237/336 [15:40<06:10,  3.74s/it] 71%|███████   | 238/336 [15:44<06:08,  3.76s/it] 71%|███████   | 239/336 [15:47<05:55,  3.66s/it] 71%|███████▏  | 240/336 [15:51<05:50,  3.65s/it]                                                  71%|███████▏  | 240/336 [15:51<05:50,  3.65s/it] 72%|███████▏  | 241/336 [15:54<05:51,  3.71s/it] 72%|███████▏  | 242/336 [15:58<05:54,  3.77s/it] 72%|███████▏  | 243/336 [16:02<05:47,  3.73s/it] 73%|███████▎  | 244/336 [16:06<05:41,  3.71s/it] 73%|███████▎  | 245/336 [16:09<05:41,  3.76s/it] 73%|███████▎  | 246/336 [16:13<05:45,  3.83s/it] 74%|███████▎  | 247/336 [16:17<05:38,  3.80s/it] 74%|███████▍  | 248/336 [16:21<05:32,  3.77s/it] 74%|███████▍  | 249/336 [16:25<05:25,  3.74s/it] 74%|███████▍  | 250/336 [16:28<05:24,  3.77s/it]                                                  74%|███████▍  | 250/336 [16:28<05:24,  3.77s/it] 75%|███████▍  | 251/336 [16:32<05:21,  3.79s/it] 75%|███████▌  | 252/336 [16:36<05:16,  3.77s/it] 75%|███████▌  | 253/336 [16:40<05:15,  3.80s/it] 76%|███████▌  | 254/336 [16:44<05:08,  3.76s/it] 76%|███████▌  | 255/336 [16:47<05:01,  3.72s/it] 76%|███████▌  | 256/336 [16:51<05:03,  3.79s/it] 76%|███████▋  | 257/336 [16:55<04:59,  3.79s/it] 77%|███████▋  | 258/336 [16:59<04:52,  3.76s/it] 77%|███████▋  | 259/336 [17:02<04:48,  3.75s/it] 77%|███████▋  | 260/336 [17:06<04:42,  3.71s/it]                                                  77%|███████▋  | 260/336 [17:06<04:42,  3.71s/it] 78%|███████▊  | 261/336 [17:10<04:37,  3.70s/it] 78%|███████▊  | 262/336 [17:13<04:34,  3.71s/it] 78%|███████▊  | 263/336 [17:17<04:32,  3.73s/it] 79%|███████▊  | 264/336 [17:21<04:29,  3.74s/it] 79%|███████▉  | 265/336 [17:25<04:24,  3.72s/it] 79%|███████▉  | 266/336 [17:28<04:21,  3.74s/it] 79%|███████▉  | 267/336 [17:32<04:20,  3.77s/it] 80%|███████▉  | 268/336 [17:36<04:15,  3.75s/it] 80%|████████  | 269/336 [17:40<04:09,  3.72s/it] 80%|████████  | 270/336 [17:43<04:06,  3.74s/it]                                                  80%|████████  | 270/336 [17:43<04:06,  3.74s/it] 81%|████████  | 271/336 [17:47<03:59,  3.69s/it] 81%|████████  | 272/336 [17:51<03:58,  3.73s/it] 81%|████████▏ | 273/336 [17:54<03:52,  3.69s/it] 82%|████████▏ | 274/336 [17:58<03:51,  3.74s/it] 82%|████████▏ | 275/336 [18:02<03:52,  3.81s/it] 82%|████████▏ | 276/336 [18:06<03:44,  3.75s/it] 82%|████████▏ | 277/336 [18:09<03:39,  3.71s/it] 83%|████████▎ | 278/336 [18:13<03:38,  3.77s/it] 83%|████████▎ | 279/336 [18:17<03:33,  3.74s/it] 83%|████████▎ | 280/336 [18:21<03:36,  3.86s/it]                                                  83%|████████▎ | 280/336 [18:21<03:36,  3.86s/it] 84%|████████▎ | 281/336 [18:25<03:31,  3.84s/it] 84%|████████▍ | 282/336 [18:29<03:25,  3.81s/it] 84%|████████▍ | 283/336 [18:32<03:20,  3.78s/it] 85%|████████▍ | 284/336 [18:36<03:15,  3.76s/it] 85%|████████▍ | 285/336 [18:40<03:12,  3.78s/it] 85%|████████▌ | 286/336 [18:44<03:07,  3.75s/it] 85%|████████▌ | 287/336 [18:47<03:02,  3.73s/it] 86%|████████▌ | 288/336 [18:51<02:57,  3.69s/it] 86%|████████▌ | 289/336 [18:55<02:56,  3.75s/it] 86%|████████▋ | 290/336 [18:58<02:51,  3.73s/it]                                                  86%|████████▋ | 290/336 [18:58<02:51,  3.73s/it] 87%|████████▋ | 291/336 [19:02<02:51,  3.80s/it] 87%|████████▋ | 292/336 [19:06<02:48,  3.82s/it] 87%|████████▋ | 293/336 [19:10<02:41,  3.76s/it] 88%|████████▊ | 294/336 [19:14<02:41,  3.84s/it] 88%|████████▊ | 295/336 [19:18<02:36,  3.82s/it] 88%|████████▊ | 296/336 [19:22<02:33,  3.83s/it] 88%|████████▊ | 297/336 [19:25<02:26,  3.77s/it] 89%|████████▊ | 298/336 [19:29<02:22,  3.75s/it] 89%|████████▉ | 299/336 [19:33<02:18,  3.74s/it] 89%|████████▉ | 300/336 [19:36<02:14,  3.74s/it]                                                  89%|████████▉ | 300/336 [19:36<02:14,  3.74s/it][INFO|trainer.py:3512] 2024-04-07 21:52:29,805 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-04-07 21:52:29,805 >>   Num examples = 100
[INFO|trainer.py:3517] 2024-04-07 21:52:29,805 >>   Batch size = 1

  0%|          | 0/100 [00:00<?, ?it/s][A
  2%|▏         | 2/100 [00:00<00:10,  9.45it/s][A
  3%|▎         | 3/100 [00:00<00:14,  6.71it/s][A
  4%|▍         | 4/100 [00:00<00:16,  5.76it/s][A
  5%|▌         | 5/100 [00:00<00:17,  5.38it/s][A
  6%|▌         | 6/100 [00:01<00:18,  5.20it/s][A
  7%|▋         | 7/100 [00:01<00:18,  5.00it/s][A
  8%|▊         | 8/100 [00:01<00:18,  4.95it/s][A
  9%|▉         | 9/100 [00:01<00:18,  4.99it/s][A
 10%|█         | 10/100 [00:01<00:18,  4.96it/s][A
 11%|█         | 11/100 [00:02<00:17,  4.97it/s][A
 12%|█▏        | 12/100 [00:02<00:19,  4.56it/s][A
 13%|█▎        | 13/100 [00:02<00:18,  4.59it/s][A
 14%|█▍        | 14/100 [00:02<00:18,  4.67it/s][A
 15%|█▌        | 15/100 [00:02<00:18,  4.69it/s][A
 16%|█▌        | 16/100 [00:03<00:17,  4.68it/s][A
 17%|█▋        | 17/100 [00:03<00:17,  4.65it/s][A
 18%|█▊        | 18/100 [00:03<00:17,  4.70it/s][A
 19%|█▉        | 19/100 [00:03<00:16,  4.81it/s][A
 20%|██        | 20/100 [00:03<00:16,  4.96it/s][A
 21%|██        | 21/100 [00:04<00:16,  4.86it/s][A
 22%|██▏       | 22/100 [00:04<00:16,  4.84it/s][A
 23%|██▎       | 23/100 [00:04<00:15,  4.84it/s][A
 24%|██▍       | 24/100 [00:04<00:15,  4.86it/s][A
 25%|██▌       | 25/100 [00:05<00:15,  4.87it/s][A
 26%|██▌       | 26/100 [00:05<00:15,  4.88it/s][A
 27%|██▋       | 27/100 [00:05<00:15,  4.83it/s][A
 28%|██▊       | 28/100 [00:05<00:14,  4.90it/s][A
 29%|██▉       | 29/100 [00:05<00:14,  4.88it/s][A
 30%|███       | 30/100 [00:06<00:14,  4.86it/s][A
 31%|███       | 31/100 [00:06<00:14,  4.82it/s][A
 32%|███▏      | 32/100 [00:06<00:14,  4.77it/s][A
 33%|███▎      | 33/100 [00:06<00:15,  4.44it/s][A
 34%|███▍      | 34/100 [00:06<00:14,  4.57it/s][A
 35%|███▌      | 35/100 [00:07<00:13,  4.64it/s][A
 36%|███▌      | 36/100 [00:07<00:14,  4.33it/s][A
 37%|███▋      | 37/100 [00:07<00:14,  4.47it/s][A
 38%|███▊      | 38/100 [00:07<00:13,  4.57it/s][A
 39%|███▉      | 39/100 [00:08<00:13,  4.68it/s][A
 40%|████      | 40/100 [00:08<00:12,  4.72it/s][A
 41%|████      | 41/100 [00:08<00:12,  4.79it/s][A
 42%|████▏     | 42/100 [00:08<00:12,  4.77it/s][A
 43%|████▎     | 43/100 [00:08<00:11,  4.82it/s][A
 44%|████▍     | 44/100 [00:09<00:11,  4.72it/s][A
 45%|████▌     | 45/100 [00:09<00:11,  4.71it/s][A
 46%|████▌     | 46/100 [00:09<00:11,  4.79it/s][A
 47%|████▋     | 47/100 [00:09<00:11,  4.80it/s][A
 48%|████▊     | 48/100 [00:09<00:10,  4.84it/s][A
 49%|████▉     | 49/100 [00:10<00:10,  4.87it/s][A
 50%|█████     | 50/100 [00:10<00:10,  4.90it/s][A
 51%|█████     | 51/100 [00:10<00:09,  4.91it/s][A
 52%|█████▏    | 52/100 [00:10<00:09,  4.85it/s][A
 53%|█████▎    | 53/100 [00:10<00:09,  4.71it/s][A
 54%|█████▍    | 54/100 [00:11<00:09,  4.79it/s][A
 55%|█████▌    | 55/100 [00:11<00:09,  4.77it/s][A
 56%|█████▌    | 56/100 [00:11<00:09,  4.80it/s][A
 57%|█████▋    | 57/100 [00:11<00:08,  4.79it/s][A
 58%|█████▊    | 58/100 [00:11<00:08,  4.76it/s][A
 59%|█████▉    | 59/100 [00:12<00:08,  4.75it/s][A
 60%|██████    | 60/100 [00:12<00:08,  4.77it/s][A
 61%|██████    | 61/100 [00:12<00:08,  4.80it/s][A
 62%|██████▏   | 62/100 [00:12<00:08,  4.62it/s][A
 63%|██████▎   | 63/100 [00:13<00:07,  4.69it/s][A
 64%|██████▍   | 64/100 [00:13<00:07,  4.74it/s][A
 65%|██████▌   | 65/100 [00:13<00:07,  4.79it/s][A
 66%|██████▌   | 66/100 [00:13<00:07,  4.51it/s][A
 67%|██████▋   | 67/100 [00:13<00:07,  4.56it/s][A
 68%|██████▊   | 68/100 [00:14<00:06,  4.65it/s][A
 69%|██████▉   | 69/100 [00:14<00:06,  4.68it/s][A
 70%|███████   | 70/100 [00:14<00:06,  4.55it/s][A
 71%|███████   | 71/100 [00:14<00:06,  4.62it/s][A
 72%|███████▏  | 72/100 [00:14<00:05,  4.67it/s][A
 73%|███████▎  | 73/100 [00:15<00:06,  4.42it/s][A
 74%|███████▍  | 74/100 [00:15<00:05,  4.51it/s][A
 75%|███████▌  | 75/100 [00:15<00:05,  4.60it/s][A
 76%|███████▌  | 76/100 [00:15<00:05,  4.71it/s][A
 77%|███████▋  | 77/100 [00:16<00:04,  4.74it/s][A
 78%|███████▊  | 78/100 [00:16<00:04,  4.76it/s][A
 79%|███████▉  | 79/100 [00:16<00:04,  4.72it/s][A
 80%|████████  | 80/100 [00:16<00:04,  4.68it/s][A
 81%|████████  | 81/100 [00:16<00:04,  4.70it/s][A
 82%|████████▏ | 82/100 [00:17<00:03,  4.74it/s][A
 83%|████████▎ | 83/100 [00:17<00:03,  4.74it/s][A
 84%|████████▍ | 84/100 [00:17<00:03,  4.82it/s][A
 85%|████████▌ | 85/100 [00:17<00:03,  4.84it/s][A
 86%|████████▌ | 86/100 [00:17<00:02,  4.86it/s][A
 87%|████████▋ | 87/100 [00:18<00:02,  4.80it/s][A
 88%|████████▊ | 88/100 [00:18<00:02,  4.83it/s][A
 89%|████████▉ | 89/100 [00:18<00:02,  4.85it/s][A
 90%|█████████ | 90/100 [00:18<00:02,  4.82it/s][A
 91%|█████████ | 91/100 [00:19<00:01,  4.73it/s][A
 92%|█████████▏| 92/100 [00:19<00:01,  4.69it/s][A
 93%|█████████▎| 93/100 [00:19<00:01,  4.78it/s][A
 94%|█████████▍| 94/100 [00:19<00:01,  4.81it/s][A
 95%|█████████▌| 95/100 [00:19<00:01,  4.87it/s][A
 96%|█████████▌| 96/100 [00:20<00:00,  4.87it/s][A
 97%|█████████▋| 97/100 [00:20<00:00,  4.87it/s][A
 98%|█████████▊| 98/100 [00:20<00:00,  4.87it/s][A
 99%|█████████▉| 99/100 [00:20<00:00,  4.55it/s][A
100%|██████████| 100/100 [00:20<00:00,  4.40it/s][A                                                 
                                                 [A 89%|████████▉ | 300/336 [19:57<02:14,  3.74s/it]
100%|██████████| 100/100 [00:20<00:00,  4.40it/s][A
                                                 [A[INFO|trainer.py:3203] 2024-04-07 21:52:50,970 >> Saving model checkpoint to ../../saves/LLaMA2-7B/lora/sft/checkpoint-300
[INFO|configuration_utils.py:726] 2024-04-07 21:52:51,677 >> loading configuration file config.json from cache at /home/wenning1/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-hf/snapshots/8a0442e81540efaeb1a0fe3e95477b5e0edfd423/config.json
[INFO|configuration_utils.py:789] 2024-04-07 21:52:51,678 >> Model config LlamaConfig {
  "_name_or_path": "meta-llama/Llama-2-7b-hf",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_position_embeddings": 4096,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "float16",
  "transformers_version": "4.39.3",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|tokenization_utils_base.py:2502] 2024-04-07 21:52:51,801 >> tokenizer config file saved in ../../saves/LLaMA2-7B/lora/sft/checkpoint-300/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-04-07 21:52:51,802 >> Special tokens file saved in ../../saves/LLaMA2-7B/lora/sft/checkpoint-300/special_tokens_map.json
 90%|████████▉ | 301/336 [20:02<06:02, 10.35s/it] 90%|████████▉ | 302/336 [20:06<04:43,  8.34s/it] 90%|█████████ | 303/336 [20:09<03:49,  6.95s/it] 90%|█████████ | 304/336 [20:13<03:13,  6.04s/it] 91%|█████████ | 305/336 [20:17<02:46,  5.36s/it] 91%|█████████ | 306/336 [20:21<02:25,  4.86s/it] 91%|█████████▏| 307/336 [20:25<02:12,  4.55s/it] 92%|█████████▏| 308/336 [20:28<02:00,  4.31s/it] 92%|█████████▏| 309/336 [20:32<01:52,  4.15s/it] 92%|█████████▏| 310/336 [20:36<01:44,  4.03s/it]                                                  92%|█████████▏| 310/336 [20:36<01:44,  4.03s/it] 93%|█████████▎| 311/336 [20:40<01:37,  3.92s/it] 93%|█████████▎| 312/336 [20:43<01:33,  3.91s/it] 93%|█████████▎| 313/336 [20:47<01:28,  3.83s/it] 93%|█████████▎| 314/336 [20:51<01:24,  3.85s/it] 94%|█████████▍| 315/336 [20:55<01:19,  3.81s/it] 94%|█████████▍| 316/336 [20:58<01:15,  3.77s/it] 94%|█████████▍| 317/336 [21:02<01:10,  3.73s/it] 95%|█████████▍| 318/336 [21:06<01:06,  3.72s/it] 95%|█████████▍| 319/336 [21:09<01:02,  3.70s/it] 95%|█████████▌| 320/336 [21:13<00:59,  3.70s/it]                                                  95%|█████████▌| 320/336 [21:13<00:59,  3.70s/it] 96%|█████████▌| 321/336 [21:17<00:55,  3.69s/it] 96%|█████████▌| 322/336 [21:20<00:51,  3.67s/it] 96%|█████████▌| 323/336 [21:24<00:48,  3.70s/it] 96%|█████████▋| 324/336 [21:28<00:44,  3.70s/it] 97%|█████████▋| 325/336 [21:32<00:41,  3.80s/it] 97%|█████████▋| 326/336 [21:36<00:38,  3.80s/it] 97%|█████████▋| 327/336 [21:40<00:34,  3.82s/it] 98%|█████████▊| 328/336 [21:43<00:30,  3.76s/it] 98%|█████████▊| 329/336 [21:47<00:26,  3.82s/it] 98%|█████████▊| 330/336 [21:51<00:22,  3.79s/it]                                                  98%|█████████▊| 330/336 [21:51<00:22,  3.79s/it] 99%|█████████▊| 331/336 [21:55<00:19,  3.84s/it] 99%|█████████▉| 332/336 [21:59<00:15,  3.88s/it] 99%|█████████▉| 333/336 [22:03<00:11,  3.84s/it] 99%|█████████▉| 334/336 [22:06<00:07,  3.80s/it]100%|█████████▉| 335/336 [22:10<00:03,  3.80s/it]100%|██████████| 336/336 [22:14<00:00,  3.77s/it][INFO|trainer.py:2231] 2024-04-07 21:55:07,261 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


[INFO|trainer.py:2436] 2024-04-07 21:55:07,261 >> Loading best model from ../../saves/LLaMA2-7B/lora/sft/checkpoint-300 (score: 0.25560736656188965).
                                                 100%|██████████| 336/336 [22:14<00:00,  3.77s/it]100%|██████████| 336/336 [22:14<00:00,  3.97s/it]
[INFO|trainer.py:3203] 2024-04-07 21:55:07,311 >> Saving model checkpoint to ../../saves/LLaMA2-7B/lora/sft
[INFO|configuration_utils.py:726] 2024-04-07 21:55:07,780 >> loading configuration file config.json from cache at /home/wenning1/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-hf/snapshots/8a0442e81540efaeb1a0fe3e95477b5e0edfd423/config.json
[INFO|configuration_utils.py:789] 2024-04-07 21:55:07,781 >> Model config LlamaConfig {
  "_name_or_path": "meta-llama/Llama-2-7b-hf",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_position_embeddings": 4096,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "float16",
  "transformers_version": "4.39.3",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|tokenization_utils_base.py:2502] 2024-04-07 21:55:07,866 >> tokenizer config file saved in ../../saves/LLaMA2-7B/lora/sft/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-04-07 21:55:07,867 >> Special tokens file saved in ../../saves/LLaMA2-7B/lora/sft/special_tokens_map.json
[INFO|trainer.py:3512] 2024-04-07 21:55:20,993 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-04-07 21:55:20,993 >>   Num examples = 100
[INFO|trainer.py:3517] 2024-04-07 21:55:20,993 >>   Batch size = 1
  0%|          | 0/100 [00:00<?, ?it/s]  2%|▏         | 2/100 [00:00<00:10,  9.34it/s]  3%|▎         | 3/100 [00:00<00:14,  6.82it/s]  4%|▍         | 4/100 [00:00<00:16,  5.88it/s]  5%|▌         | 5/100 [00:00<00:17,  5.54it/s]  6%|▌         | 6/100 [00:01<00:18,  5.19it/s]  7%|▋         | 7/100 [00:01<00:18,  4.99it/s]  8%|▊         | 8/100 [00:01<00:18,  4.87it/s]  9%|▉         | 9/100 [00:01<00:18,  4.97it/s] 10%|█         | 10/100 [00:01<00:18,  4.94it/s] 11%|█         | 11/100 [00:02<00:17,  4.98it/s] 12%|█▏        | 12/100 [00:02<00:19,  4.61it/s] 13%|█▎        | 13/100 [00:02<00:18,  4.65it/s] 14%|█▍        | 14/100 [00:02<00:18,  4.73it/s] 15%|█▌        | 15/100 [00:02<00:18,  4.71it/s] 16%|█▌        | 16/100 [00:03<00:17,  4.70it/s] 17%|█▋        | 17/100 [00:03<00:17,  4.69it/s] 18%|█▊        | 18/100 [00:03<00:17,  4.74it/s] 19%|█▉        | 19/100 [00:03<00:16,  4.80it/s] 20%|██        | 20/100 [00:03<00:16,  4.90it/s] 21%|██        | 21/100 [00:04<00:16,  4.79it/s] 22%|██▏       | 22/100 [00:04<00:16,  4.73it/s] 23%|██▎       | 23/100 [00:04<00:16,  4.80it/s] 24%|██▍       | 24/100 [00:04<00:15,  4.91it/s] 25%|██▌       | 25/100 [00:05<00:15,  4.90it/s] 26%|██▌       | 26/100 [00:05<00:14,  4.96it/s] 27%|██▋       | 27/100 [00:05<00:14,  4.89it/s] 28%|██▊       | 28/100 [00:05<00:14,  4.97it/s] 29%|██▉       | 29/100 [00:05<00:14,  5.01it/s] 30%|███       | 30/100 [00:06<00:13,  5.01it/s] 31%|███       | 31/100 [00:06<00:13,  4.96it/s] 32%|███▏      | 32/100 [00:06<00:14,  4.83it/s] 33%|███▎      | 33/100 [00:06<00:14,  4.54it/s] 34%|███▍      | 34/100 [00:06<00:14,  4.67it/s] 35%|███▌      | 35/100 [00:07<00:13,  4.69it/s] 36%|███▌      | 36/100 [00:07<00:14,  4.42it/s] 37%|███▋      | 37/100 [00:07<00:14,  4.47it/s] 38%|███▊      | 38/100 [00:07<00:13,  4.54it/s] 39%|███▉      | 39/100 [00:07<00:13,  4.66it/s] 40%|████      | 40/100 [00:08<00:12,  4.76it/s] 41%|████      | 41/100 [00:08<00:12,  4.82it/s] 42%|████▏     | 42/100 [00:08<00:12,  4.78it/s] 43%|████▎     | 43/100 [00:08<00:11,  4.79it/s] 44%|████▍     | 44/100 [00:09<00:11,  4.75it/s] 45%|████▌     | 45/100 [00:09<00:11,  4.82it/s] 46%|████▌     | 46/100 [00:09<00:11,  4.84it/s] 47%|████▋     | 47/100 [00:09<00:10,  4.88it/s] 48%|████▊     | 48/100 [00:09<00:10,  4.89it/s] 49%|████▉     | 49/100 [00:10<00:10,  4.89it/s] 50%|█████     | 50/100 [00:10<00:10,  4.89it/s] 51%|█████     | 51/100 [00:10<00:10,  4.88it/s] 52%|█████▏    | 52/100 [00:10<00:09,  4.80it/s] 53%|█████▎    | 53/100 [00:10<00:09,  4.75it/s] 54%|█████▍    | 54/100 [00:11<00:09,  4.79it/s] 55%|█████▌    | 55/100 [00:11<00:09,  4.80it/s] 56%|█████▌    | 56/100 [00:11<00:09,  4.81it/s] 57%|█████▋    | 57/100 [00:11<00:08,  4.83it/s] 58%|█████▊    | 58/100 [00:11<00:08,  4.74it/s] 59%|█████▉    | 59/100 [00:12<00:08,  4.75it/s] 60%|██████    | 60/100 [00:12<00:08,  4.72it/s] 61%|██████    | 61/100 [00:12<00:08,  4.77it/s] 62%|██████▏   | 62/100 [00:12<00:07,  4.83it/s] 63%|██████▎   | 63/100 [00:12<00:07,  4.84it/s] 64%|██████▍   | 64/100 [00:13<00:07,  4.85it/s] 65%|██████▌   | 65/100 [00:13<00:07,  4.85it/s] 66%|██████▌   | 66/100 [00:13<00:07,  4.47it/s] 67%|██████▋   | 67/100 [00:13<00:07,  4.58it/s] 68%|██████▊   | 68/100 [00:14<00:06,  4.69it/s] 69%|██████▉   | 69/100 [00:14<00:06,  4.70it/s] 70%|███████   | 70/100 [00:14<00:06,  4.73it/s] 71%|███████   | 71/100 [00:14<00:06,  4.74it/s] 72%|███████▏  | 72/100 [00:14<00:05,  4.78it/s] 73%|███████▎  | 73/100 [00:15<00:06,  4.46it/s] 74%|███████▍  | 74/100 [00:15<00:05,  4.59it/s] 75%|███████▌  | 75/100 [00:15<00:05,  4.67it/s] 76%|███████▌  | 76/100 [00:15<00:05,  4.74it/s] 77%|███████▋  | 77/100 [00:15<00:04,  4.76it/s] 78%|███████▊  | 78/100 [00:16<00:04,  4.79it/s] 79%|███████▉  | 79/100 [00:16<00:04,  4.78it/s] 80%|████████  | 80/100 [00:16<00:04,  4.83it/s] 81%|████████  | 81/100 [00:16<00:03,  4.77it/s] 82%|████████▏ | 82/100 [00:16<00:03,  4.81it/s] 83%|████████▎ | 83/100 [00:17<00:03,  4.80it/s] 84%|████████▍ | 84/100 [00:17<00:03,  4.80it/s] 85%|████████▌ | 85/100 [00:17<00:03,  4.83it/s] 86%|████████▌ | 86/100 [00:17<00:02,  4.84it/s] 87%|████████▋ | 87/100 [00:18<00:02,  4.82it/s] 88%|████████▊ | 88/100 [00:18<00:02,  4.82it/s] 89%|████████▉ | 89/100 [00:18<00:02,  4.84it/s] 90%|█████████ | 90/100 [00:18<00:02,  4.81it/s] 91%|█████████ | 91/100 [00:18<00:01,  4.84it/s] 92%|█████████▏| 92/100 [00:19<00:01,  4.81it/s] 93%|█████████▎| 93/100 [00:19<00:01,  4.86it/s] 94%|█████████▍| 94/100 [00:19<00:01,  4.85it/s] 95%|█████████▌| 95/100 [00:19<00:01,  4.86it/s] 96%|█████████▌| 96/100 [00:19<00:00,  4.85it/s] 97%|█████████▋| 97/100 [00:20<00:00,  4.85it/s] 98%|█████████▊| 98/100 [00:20<00:00,  4.80it/s] 99%|█████████▉| 99/100 [00:20<00:00,  4.48it/s]100%|██████████| 100/100 [00:20<00:00,  4.30it/s]100%|██████████| 100/100 [00:20<00:00,  4.80it/s]
[INFO|modelcard.py:450] 2024-04-07 21:55:42,037 >> Dropping the following result as it does not have all the necessary fields:
{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}
