[INFO|tokenization_utils_base.py:2084] 2024-04-07 19:28:45,800 >> loading file tokenizer.model from cache at /home/wenning1/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-hf/snapshots/8a0442e81540efaeb1a0fe3e95477b5e0edfd423/tokenizer.model
[INFO|tokenization_utils_base.py:2084] 2024-04-07 19:28:45,800 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:2084] 2024-04-07 19:28:45,800 >> loading file special_tokens_map.json from cache at /home/wenning1/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-hf/snapshots/8a0442e81540efaeb1a0fe3e95477b5e0edfd423/special_tokens_map.json
[INFO|tokenization_utils_base.py:2084] 2024-04-07 19:28:45,800 >> loading file tokenizer_config.json from cache at /home/wenning1/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-hf/snapshots/8a0442e81540efaeb1a0fe3e95477b5e0edfd423/tokenizer_config.json
[INFO|tokenization_utils_base.py:2084] 2024-04-07 19:28:45,800 >> loading file tokenizer.json from cache at /home/wenning1/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-hf/snapshots/8a0442e81540efaeb1a0fe3e95477b5e0edfd423/tokenizer.json
Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 1000 examples [00:00, 29909.54 examples/s]
Converting format of dataset (num_proc=16):   0%|          | 0/1000 [00:00<?, ? examples/s]Converting format of dataset (num_proc=16):  13%|█▎        | 126/1000 [00:00<00:00, 1241.19 examples/s]Converting format of dataset (num_proc=16): 100%|██████████| 1000/1000 [00:00<00:00, 3851.99 examples/s]
Running tokenizer on dataset (num_proc=16):   0%|          | 0/1000 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   6%|▋         | 63/1000 [00:00<00:06, 153.89 examples/s]Running tokenizer on dataset (num_proc=16):  25%|██▌       | 252/1000 [00:00<00:01, 593.97 examples/s]Running tokenizer on dataset (num_proc=16):  50%|█████     | 504/1000 [00:00<00:00, 1080.13 examples/s]Running tokenizer on dataset (num_proc=16): 100%|██████████| 1000/1000 [00:00<00:00, 1279.77 examples/s]
[INFO|configuration_utils.py:726] 2024-04-07 19:28:48,490 >> loading configuration file config.json from cache at /home/wenning1/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-hf/snapshots/8a0442e81540efaeb1a0fe3e95477b5e0edfd423/config.json
[INFO|configuration_utils.py:789] 2024-04-07 19:28:48,493 >> Model config LlamaConfig {
  "_name_or_path": "meta-llama/Llama-2-7b-hf",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_position_embeddings": 4096,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "float16",
  "transformers_version": "4.39.3",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|modeling_utils.py:3283] 2024-04-07 19:28:48,522 >> loading weights file model.safetensors from cache at /home/wenning1/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-hf/snapshots/8a0442e81540efaeb1a0fe3e95477b5e0edfd423/model.safetensors.index.json
[INFO|modeling_utils.py:1417] 2024-04-07 19:28:48,523 >> Instantiating LlamaForCausalLM model under default dtype torch.float16.
[INFO|configuration_utils.py:928] 2024-04-07 19:28:48,524 >> Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": 2
}

Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:15<00:15, 15.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:18<00:00,  7.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:18<00:00,  9.03s/it]
[INFO|modeling_utils.py:4024] 2024-04-07 19:29:06,799 >> All model checkpoint weights were used when initializing LlamaForCausalLM.

[INFO|modeling_utils.py:4032] 2024-04-07 19:29:06,799 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at meta-llama/Llama-2-7b-hf.
If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.
[INFO|configuration_utils.py:883] 2024-04-07 19:29:07,532 >> loading configuration file generation_config.json from cache at /home/wenning1/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-hf/snapshots/8a0442e81540efaeb1a0fe3e95477b5e0edfd423/generation_config.json
[INFO|configuration_utils.py:928] 2024-04-07 19:29:07,533 >> Generate config GenerationConfig {
  "bos_token_id": 1,
  "do_sample": true,
  "eos_token_id": 2,
  "max_length": 4096,
  "pad_token_id": 0,
  "temperature": 0.6,
  "top_p": 0.9
}

/home/wenning1/.local/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:607] 2024-04-07 19:29:07,768 >> Using auto half precision backend
[INFO|trainer.py:1969] 2024-04-07 19:29:07,981 >> ***** Running training *****
[INFO|trainer.py:1970] 2024-04-07 19:29:07,981 >>   Num examples = 900
[INFO|trainer.py:1971] 2024-04-07 19:29:07,981 >>   Num Epochs = 3
[INFO|trainer.py:1972] 2024-04-07 19:29:07,981 >>   Instantaneous batch size per device = 1
[INFO|trainer.py:1975] 2024-04-07 19:29:07,981 >>   Total train batch size (w. parallel, distributed & accumulation) = 8
[INFO|trainer.py:1976] 2024-04-07 19:29:07,981 >>   Gradient Accumulation steps = 8
[INFO|trainer.py:1977] 2024-04-07 19:29:07,981 >>   Total optimization steps = 336
[INFO|trainer.py:1978] 2024-04-07 19:29:07,982 >>   Number of trainable parameters = 4,194,304
  0%|          | 0/336 [00:00<?, ?it/s]  0%|          | 1/336 [00:08<47:25,  8.49s/it]  1%|          | 2/336 [00:12<32:13,  5.79s/it]  1%|          | 3/336 [00:16<27:06,  4.88s/it]  1%|          | 4/336 [00:19<24:22,  4.41s/it]  1%|▏         | 5/336 [00:23<22:52,  4.15s/it]  2%|▏         | 6/336 [00:27<22:06,  4.02s/it]  2%|▏         | 7/336 [00:30<21:22,  3.90s/it]  2%|▏         | 8/336 [00:34<20:52,  3.82s/it]  3%|▎         | 9/336 [00:38<20:37,  3.78s/it]  3%|▎         | 10/336 [00:41<20:19,  3.74s/it]                                                  3%|▎         | 10/336 [00:41<20:19,  3.74s/it]  3%|▎         | 11/336 [00:45<20:08,  3.72s/it]  4%|▎         | 12/336 [00:49<19:55,  3.69s/it]  4%|▍         | 13/336 [00:53<20:04,  3.73s/it]  4%|▍         | 14/336 [00:56<19:57,  3.72s/it]  4%|▍         | 15/336 [01:00<20:04,  3.75s/it]  5%|▍         | 16/336 [01:04<20:07,  3.77s/it]  5%|▌         | 17/336 [01:08<19:54,  3.74s/it]  5%|▌         | 18/336 [01:12<20:10,  3.81s/it]  6%|▌         | 19/336 [01:15<19:59,  3.78s/it]  6%|▌         | 20/336 [01:19<19:46,  3.76s/it]                                                  6%|▌         | 20/336 [01:19<19:46,  3.76s/it]  6%|▋         | 21/336 [01:23<19:38,  3.74s/it]  7%|▋         | 22/336 [01:26<19:37,  3.75s/it]  7%|▋         | 23/336 [01:30<19:59,  3.83s/it]  7%|▋         | 24/336 [01:34<19:35,  3.77s/it]  7%|▋         | 25/336 [01:38<19:41,  3.80s/it]  8%|▊         | 26/336 [01:42<19:38,  3.80s/it]  8%|▊         | 27/336 [01:45<19:24,  3.77s/it]  8%|▊         | 28/336 [01:49<19:11,  3.74s/it]  9%|▊         | 29/336 [01:53<19:14,  3.76s/it]  9%|▉         | 30/336 [01:57<19:08,  3.75s/it]                                                  9%|▉         | 30/336 [01:57<19:08,  3.75s/it]  9%|▉         | 31/336 [02:00<18:56,  3.73s/it] 10%|▉         | 32/336 [02:04<18:49,  3.71s/it] 10%|▉         | 33/336 [02:08<18:34,  3.68s/it] 10%|█         | 34/336 [02:12<18:52,  3.75s/it] 10%|█         | 35/336 [02:15<19:01,  3.79s/it] 11%|█         | 36/336 [02:19<18:43,  3.75s/it] 11%|█         | 37/336 [02:23<18:29,  3.71s/it] 11%|█▏        | 38/336 [02:27<18:47,  3.78s/it] 12%|█▏        | 39/336 [02:31<19:07,  3.86s/it] 12%|█▏        | 40/336 [02:35<19:15,  3.90s/it]                                                 12%|█▏        | 40/336 [02:35<19:15,  3.90s/it] 12%|█▏        | 41/336 [02:39<19:04,  3.88s/it] 12%|█▎        | 42/336 [02:42<18:58,  3.87s/it] 13%|█▎        | 43/336 [02:46<18:56,  3.88s/it] 13%|█▎        | 44/336 [02:50<18:52,  3.88s/it] 13%|█▎        | 45/336 [02:54<18:34,  3.83s/it] 14%|█▎        | 46/336 [02:58<18:12,  3.77s/it] 14%|█▍        | 47/336 [03:01<18:06,  3.76s/it] 14%|█▍        | 48/336 [03:05<18:02,  3.76s/it] 15%|█▍        | 49/336 [03:09<18:01,  3.77s/it] 15%|█▍        | 50/336 [03:13<17:56,  3.76s/it]                                                 15%|█▍        | 50/336 [03:13<17:56,  3.76s/it] 15%|█▌        | 51/336 [03:16<18:03,  3.80s/it] 15%|█▌        | 52/336 [03:21<18:23,  3.89s/it] 16%|█▌        | 53/336 [03:24<18:04,  3.83s/it] 16%|█▌        | 54/336 [03:28<18:01,  3.84s/it] 16%|█▋        | 55/336 [03:32<17:39,  3.77s/it] 17%|█▋        | 56/336 [03:35<17:29,  3.75s/it] 17%|█▋        | 57/336 [03:39<17:19,  3.73s/it] 17%|█▋        | 58/336 [03:43<17:03,  3.68s/it] 18%|█▊        | 59/336 [03:46<17:09,  3.72s/it] 18%|█▊        | 60/336 [03:50<17:03,  3.71s/it]                                                 18%|█▊        | 60/336 [03:50<17:03,  3.71s/it] 18%|█▊        | 61/336 [03:54<16:49,  3.67s/it] 18%|█▊        | 62/336 [03:58<16:59,  3.72s/it] 19%|█▉        | 63/336 [04:01<16:57,  3.73s/it] 19%|█▉        | 64/336 [04:05<17:00,  3.75s/it] 19%|█▉        | 65/336 [04:09<16:58,  3.76s/it] 20%|█▉        | 66/336 [04:13<16:49,  3.74s/it] 20%|█▉        | 67/336 [04:16<16:43,  3.73s/it] 20%|██        | 68/336 [04:20<16:51,  3.77s/it] 21%|██        | 69/336 [04:24<16:42,  3.76s/it] 21%|██        | 70/336 [04:28<16:49,  3.79s/it]                                                 21%|██        | 70/336 [04:28<16:49,  3.79s/it] 21%|██        | 71/336 [04:31<16:34,  3.75s/it] 21%|██▏       | 72/336 [04:35<16:07,  3.67s/it] 22%|██▏       | 73/336 [04:39<16:07,  3.68s/it] 22%|██▏       | 74/336 [04:42<16:02,  3.67s/it] 22%|██▏       | 75/336 [04:46<16:04,  3.69s/it] 23%|██▎       | 76/336 [04:50<15:59,  3.69s/it] 23%|██▎       | 77/336 [04:53<15:52,  3.68s/it] 23%|██▎       | 78/336 [04:57<15:44,  3.66s/it] 24%|██▎       | 79/336 [05:01<15:53,  3.71s/it] 24%|██▍       | 80/336 [05:05<16:08,  3.78s/it]                                                 24%|██▍       | 80/336 [05:05<16:08,  3.78s/it] 24%|██▍       | 81/336 [05:08<15:57,  3.75s/it] 24%|██▍       | 82/336 [05:12<15:55,  3.76s/it] 25%|██▍       | 83/336 [05:16<15:36,  3.70s/it] 25%|██▌       | 84/336 [05:19<15:32,  3.70s/it] 25%|██▌       | 85/336 [05:23<15:30,  3.71s/it] 26%|██▌       | 86/336 [05:27<15:21,  3.69s/it] 26%|██▌       | 87/336 [05:30<15:17,  3.69s/it] 26%|██▌       | 88/336 [05:34<15:38,  3.78s/it] 26%|██▋       | 89/336 [05:38<15:33,  3.78s/it] 27%|██▋       | 90/336 [05:42<15:36,  3.81s/it]                                                 27%|██▋       | 90/336 [05:42<15:36,  3.81s/it] 27%|██▋       | 91/336 [05:46<15:27,  3.79s/it] 27%|██▋       | 92/336 [05:50<15:47,  3.88s/it] 28%|██▊       | 93/336 [05:54<15:26,  3.81s/it] 28%|██▊       | 94/336 [05:57<15:10,  3.76s/it] 28%|██▊       | 95/336 [06:01<15:12,  3.79s/it] 29%|██▊       | 96/336 [06:05<15:10,  3.80s/it] 29%|██▉       | 97/336 [06:09<15:07,  3.80s/it] 29%|██▉       | 98/336 [06:13<15:07,  3.81s/it] 29%|██▉       | 99/336 [06:16<14:52,  3.76s/it] 30%|██▉       | 100/336 [06:20<14:52,  3.78s/it]                                                  30%|██▉       | 100/336 [06:20<14:52,  3.78s/it][INFO|trainer.py:3512] 2024-04-07 19:35:28,529 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-04-07 19:35:28,529 >>   Num examples = 100
[INFO|trainer.py:3517] 2024-04-07 19:35:28,529 >>   Batch size = 1

  0%|          | 0/100 [00:00<?, ?it/s][A
  2%|▏         | 2/100 [00:00<00:10,  8.98it/s][A
  3%|▎         | 3/100 [00:00<00:15,  6.42it/s][A
  4%|▍         | 4/100 [00:00<00:17,  5.48it/s][A
  5%|▌         | 5/100 [00:00<00:18,  5.16it/s][A
  6%|▌         | 6/100 [00:01<00:19,  4.93it/s][A
  7%|▋         | 7/100 [00:01<00:19,  4.85it/s][A
  8%|▊         | 8/100 [00:01<00:19,  4.77it/s][A
  9%|▉         | 9/100 [00:01<00:18,  4.86it/s][A
 10%|█         | 10/100 [00:01<00:18,  4.81it/s][A
 11%|█         | 11/100 [00:02<00:18,  4.82it/s][A
 12%|█▏        | 12/100 [00:02<00:19,  4.51it/s][A
 13%|█▎        | 13/100 [00:02<00:19,  4.50it/s][A
 14%|█▍        | 14/100 [00:02<00:18,  4.55it/s][A
 15%|█▌        | 15/100 [00:03<00:18,  4.62it/s][A
 16%|█▌        | 16/100 [00:03<00:18,  4.66it/s][A
 17%|█▋        | 17/100 [00:03<00:17,  4.68it/s][A
 18%|█▊        | 18/100 [00:03<00:17,  4.72it/s][A
 19%|█▉        | 19/100 [00:03<00:16,  4.81it/s][A
 20%|██        | 20/100 [00:04<00:16,  4.91it/s][A
 21%|██        | 21/100 [00:04<00:16,  4.82it/s][A
 22%|██▏       | 22/100 [00:04<00:16,  4.67it/s][A
 23%|██▎       | 23/100 [00:04<00:17,  4.46it/s][A
 24%|██▍       | 24/100 [00:04<00:17,  4.46it/s][A
 25%|██▌       | 25/100 [00:05<00:18,  4.12it/s][A
 26%|██▌       | 26/100 [00:05<00:17,  4.24it/s][A
 27%|██▋       | 27/100 [00:05<00:17,  4.16it/s][A
 28%|██▊       | 28/100 [00:05<00:16,  4.28it/s][A
 29%|██▉       | 29/100 [00:06<00:17,  3.95it/s][A
 30%|███       | 30/100 [00:06<00:17,  3.99it/s][A
 31%|███       | 31/100 [00:06<00:17,  4.00it/s][A
 32%|███▏      | 32/100 [00:07<00:18,  3.58it/s][A
 33%|███▎      | 33/100 [00:07<00:18,  3.57it/s][A
 34%|███▍      | 34/100 [00:07<00:18,  3.65it/s][A
 35%|███▌      | 35/100 [00:07<00:18,  3.55it/s][A
 36%|███▌      | 36/100 [00:08<00:18,  3.51it/s][A
 37%|███▋      | 37/100 [00:08<00:17,  3.63it/s][A
 38%|███▊      | 38/100 [00:08<00:17,  3.59it/s][A
 39%|███▉      | 39/100 [00:09<00:16,  3.69it/s][A
 40%|████      | 40/100 [00:09<00:16,  3.69it/s][A
 41%|████      | 41/100 [00:09<00:15,  3.84it/s][A
 42%|████▏     | 42/100 [00:09<00:15,  3.71it/s][A
 43%|████▎     | 43/100 [00:10<00:15,  3.78it/s][A
 44%|████▍     | 44/100 [00:10<00:14,  3.80it/s][A
 45%|████▌     | 45/100 [00:10<00:15,  3.51it/s][A
 46%|████▌     | 46/100 [00:10<00:14,  3.61it/s][A
 47%|████▋     | 47/100 [00:11<00:14,  3.72it/s][A
 48%|████▊     | 48/100 [00:11<00:14,  3.67it/s][A
 49%|████▉     | 49/100 [00:11<00:13,  3.74it/s][A
 50%|█████     | 50/100 [00:11<00:13,  3.85it/s][A
 51%|█████     | 51/100 [00:12<00:12,  3.84it/s][A
 52%|█████▏    | 52/100 [00:12<00:13,  3.61it/s][A
 53%|█████▎    | 53/100 [00:12<00:12,  3.65it/s][A
 54%|█████▍    | 54/100 [00:13<00:12,  3.82it/s][A
 55%|█████▌    | 55/100 [00:13<00:12,  3.68it/s][A
 56%|█████▌    | 56/100 [00:13<00:11,  3.82it/s][A
 57%|█████▋    | 57/100 [00:13<00:10,  3.93it/s][A
 58%|█████▊    | 58/100 [00:14<00:10,  4.03it/s][A
 59%|█████▉    | 59/100 [00:14<00:12,  3.40it/s][A
 60%|██████    | 60/100 [00:14<00:12,  3.24it/s][A
 61%|██████    | 61/100 [00:15<00:11,  3.47it/s][A
 62%|██████▏   | 62/100 [00:15<00:11,  3.36it/s][A
 63%|██████▎   | 63/100 [00:15<00:10,  3.56it/s][A
 64%|██████▍   | 64/100 [00:15<00:10,  3.37it/s][A
 65%|██████▌   | 65/100 [00:16<00:10,  3.39it/s][A
 66%|██████▌   | 66/100 [00:16<00:10,  3.31it/s][A
 67%|██████▋   | 67/100 [00:16<00:09,  3.48it/s][A
 68%|██████▊   | 68/100 [00:17<00:08,  3.67it/s][A
 69%|██████▉   | 69/100 [00:17<00:08,  3.56it/s][A
 70%|███████   | 70/100 [00:17<00:08,  3.70it/s][A
 71%|███████   | 71/100 [00:17<00:07,  3.77it/s][A
 72%|███████▏  | 72/100 [00:18<00:07,  3.87it/s][A
 73%|███████▎  | 73/100 [00:18<00:07,  3.67it/s][A
 74%|███████▍  | 74/100 [00:18<00:07,  3.71it/s][A
 75%|███████▌  | 75/100 [00:18<00:06,  3.80it/s][A
 76%|███████▌  | 76/100 [00:19<00:06,  3.66it/s][A
 77%|███████▋  | 77/100 [00:19<00:06,  3.70it/s][A
 78%|███████▊  | 78/100 [00:19<00:05,  3.87it/s][A
 79%|███████▉  | 79/100 [00:19<00:05,  3.94it/s][A
 80%|████████  | 80/100 [00:20<00:05,  3.76it/s][A
 81%|████████  | 81/100 [00:20<00:05,  3.79it/s][A
 82%|████████▏ | 82/100 [00:20<00:04,  3.87it/s][A
 83%|████████▎ | 83/100 [00:21<00:04,  3.69it/s][A
 84%|████████▍ | 84/100 [00:21<00:04,  3.73it/s][A
 85%|████████▌ | 85/100 [00:21<00:03,  3.77it/s][A
 86%|████████▌ | 86/100 [00:21<00:03,  3.86it/s][A
 87%|████████▋ | 87/100 [00:22<00:03,  3.54it/s][A
 88%|████████▊ | 88/100 [00:22<00:03,  3.71it/s][A
 89%|████████▉ | 89/100 [00:22<00:02,  3.74it/s][A
 90%|█████████ | 90/100 [00:22<00:02,  3.65it/s][A
 91%|█████████ | 91/100 [00:23<00:02,  3.76it/s][A
 92%|█████████▏| 92/100 [00:23<00:02,  3.83it/s][A
 93%|█████████▎| 93/100 [00:23<00:01,  3.75it/s][A
 94%|█████████▍| 94/100 [00:24<00:01,  3.46it/s][A
 95%|█████████▌| 95/100 [00:24<00:01,  3.63it/s][A
 96%|█████████▌| 96/100 [00:24<00:01,  3.71it/s][A
 97%|█████████▋| 97/100 [00:24<00:00,  3.47it/s][A
 98%|█████████▊| 98/100 [00:25<00:00,  3.53it/s][A
 99%|█████████▉| 99/100 [00:25<00:00,  3.50it/s][A
100%|██████████| 100/100 [00:25<00:00,  3.32it/s][A                                                 
                                                 [A 30%|██▉       | 100/336 [06:46<14:52,  3.78s/it]
100%|██████████| 100/100 [00:25<00:00,  3.32it/s][A
                                                 [A[INFO|trainer.py:3203] 2024-04-07 19:35:54,507 >> Saving model checkpoint to ../../saves/LLaMA2-7B/lora/01_sft/checkpoint-100
[INFO|configuration_utils.py:726] 2024-04-07 19:35:55,449 >> loading configuration file config.json from cache at /home/wenning1/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-hf/snapshots/8a0442e81540efaeb1a0fe3e95477b5e0edfd423/config.json
[INFO|configuration_utils.py:789] 2024-04-07 19:35:55,450 >> Model config LlamaConfig {
  "_name_or_path": "meta-llama/Llama-2-7b-hf",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_position_embeddings": 4096,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "float16",
  "transformers_version": "4.39.3",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|tokenization_utils_base.py:2502] 2024-04-07 19:35:55,541 >> tokenizer config file saved in ../../saves/LLaMA2-7B/lora/01_sft/checkpoint-100/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-04-07 19:35:55,541 >> Special tokens file saved in ../../saves/LLaMA2-7B/lora/01_sft/checkpoint-100/special_tokens_map.json
 30%|███       | 101/336 [06:51<46:28, 11.86s/it] 30%|███       | 102/336 [06:55<36:46,  9.43s/it] 31%|███       | 103/336 [06:58<29:59,  7.72s/it] 31%|███       | 104/336 [07:02<25:11,  6.52s/it] 31%|███▏      | 105/336 [07:06<22:01,  5.72s/it] 32%|███▏      | 106/336 [07:10<19:51,  5.18s/it] 32%|███▏      | 107/336 [07:13<18:04,  4.74s/it] 32%|███▏      | 108/336 [07:17<16:44,  4.41s/it] 32%|███▏      | 109/336 [07:21<15:48,  4.18s/it] 33%|███▎      | 110/336 [07:24<15:08,  4.02s/it]                                                  33%|███▎      | 110/336 [07:24<15:08,  4.02s/it] 33%|███▎      | 111/336 [07:28<14:40,  3.91s/it] 33%|███▎      | 112/336 [07:32<14:20,  3.84s/it] 34%|███▎      | 113/336 [07:35<14:03,  3.78s/it] 34%|███▍      | 114/336 [07:39<13:56,  3.77s/it] 34%|███▍      | 115/336 [07:43<13:35,  3.69s/it] 35%|███▍      | 116/336 [07:46<13:37,  3.71s/it] 35%|███▍      | 117/336 [07:50<13:29,  3.70s/it] 35%|███▌      | 118/336 [07:54<13:29,  3.71s/it] 35%|███▌      | 119/336 [07:57<13:25,  3.71s/it] 36%|███▌      | 120/336 [08:01<13:30,  3.75s/it]                                                  36%|███▌      | 120/336 [08:01<13:30,  3.75s/it] 36%|███▌      | 121/336 [08:05<13:18,  3.71s/it] 36%|███▋      | 122/336 [08:09<13:22,  3.75s/it] 37%|███▋      | 123/336 [08:13<13:20,  3.76s/it] 37%|███▋      | 124/336 [08:16<13:17,  3.76s/it] 37%|███▋      | 125/336 [08:20<13:06,  3.73s/it] 38%|███▊      | 126/336 [08:24<13:06,  3.75s/it] 38%|███▊      | 127/336 [08:28<13:07,  3.77s/it] 38%|███▊      | 128/336 [08:31<13:06,  3.78s/it] 38%|███▊      | 129/336 [08:35<12:55,  3.75s/it] 39%|███▊      | 130/336 [08:39<12:52,  3.75s/it]                                                  39%|███▊      | 130/336 [08:39<12:52,  3.75s/it] 39%|███▉      | 131/336 [08:42<12:43,  3.72s/it] 39%|███▉      | 132/336 [08:46<12:30,  3.68s/it] 40%|███▉      | 133/336 [08:50<12:25,  3.67s/it] 40%|███▉      | 134/336 [08:54<12:33,  3.73s/it] 40%|████      | 135/336 [08:57<12:22,  3.70s/it] 40%|████      | 136/336 [09:01<12:24,  3.72s/it] 41%|████      | 137/336 [09:05<12:13,  3.69s/it] 41%|████      | 138/336 [09:08<12:06,  3.67s/it] 41%|████▏     | 139/336 [09:12<12:02,  3.67s/it] 42%|████▏     | 140/336 [09:15<11:53,  3.64s/it]                                                  42%|████▏     | 140/336 [09:15<11:53,  3.64s/it] 42%|████▏     | 141/336 [09:19<11:54,  3.66s/it] 42%|████▏     | 142/336 [09:23<11:48,  3.65s/it] 43%|████▎     | 143/336 [09:26<11:46,  3.66s/it] 43%|████▎     | 144/336 [09:30<11:44,  3.67s/it] 43%|████▎     | 145/336 [09:34<11:43,  3.68s/it] 43%|████▎     | 146/336 [09:38<11:44,  3.71s/it] 44%|████▍     | 147/336 [09:41<11:38,  3.70s/it] 44%|████▍     | 148/336 [09:45<11:37,  3.71s/it] 44%|████▍     | 149/336 [09:49<11:38,  3.73s/it] 45%|████▍     | 150/336 [09:53<11:32,  3.73s/it]                                                  45%|████▍     | 150/336 [09:53<11:32,  3.73s/it] 45%|████▍     | 151/336 [09:56<11:24,  3.70s/it] 45%|████▌     | 152/336 [10:00<11:24,  3.72s/it] 46%|████▌     | 153/336 [10:04<11:15,  3.69s/it] 46%|████▌     | 154/336 [10:07<11:12,  3.69s/it] 46%|████▌     | 155/336 [10:11<11:13,  3.72s/it] 46%|████▋     | 156/336 [10:15<11:08,  3.71s/it] 47%|████▋     | 157/336 [10:18<11:04,  3.71s/it] 47%|████▋     | 158/336 [10:22<10:58,  3.70s/it] 47%|████▋     | 159/336 [10:26<11:07,  3.77s/it] 48%|████▊     | 160/336 [10:30<11:01,  3.76s/it]                                                  48%|████▊     | 160/336 [10:30<11:01,  3.76s/it] 48%|████▊     | 161/336 [10:34<10:54,  3.74s/it] 48%|████▊     | 162/336 [10:37<10:48,  3.72s/it] 49%|████▊     | 163/336 [10:41<10:50,  3.76s/it] 49%|████▉     | 164/336 [10:45<10:49,  3.78s/it] 49%|████▉     | 165/336 [10:49<10:42,  3.76s/it] 49%|████▉     | 166/336 [10:52<10:34,  3.73s/it] 50%|████▉     | 167/336 [10:56<10:21,  3.68s/it] 50%|█████     | 168/336 [10:59<10:17,  3.67s/it] 50%|█████     | 169/336 [11:03<10:11,  3.66s/it] 51%|█████     | 170/336 [11:07<10:03,  3.64s/it]                                                  51%|█████     | 170/336 [11:07<10:03,  3.64s/it] 51%|█████     | 171/336 [11:10<10:00,  3.64s/it] 51%|█████     | 172/336 [11:14<10:09,  3.71s/it] 51%|█████▏    | 173/336 [11:18<10:03,  3.70s/it] 52%|█████▏    | 174/336 [11:22<10:04,  3.73s/it] 52%|█████▏    | 175/336 [11:25<09:51,  3.68s/it] 52%|█████▏    | 176/336 [11:29<09:54,  3.72s/it] 53%|█████▎    | 177/336 [11:33<09:54,  3.74s/it] 53%|█████▎    | 178/336 [11:37<09:57,  3.78s/it] 53%|█████▎    | 179/336 [11:41<09:54,  3.78s/it] 54%|█████▎    | 180/336 [11:44<09:44,  3.74s/it]                                                  54%|█████▎    | 180/336 [11:44<09:44,  3.74s/it] 54%|█████▍    | 181/336 [11:48<09:34,  3.71s/it] 54%|█████▍    | 182/336 [11:52<09:34,  3.73s/it] 54%|█████▍    | 183/336 [11:55<09:26,  3.70s/it] 55%|█████▍    | 184/336 [11:59<09:25,  3.72s/it] 55%|█████▌    | 185/336 [12:03<09:19,  3.71s/it] 55%|█████▌    | 186/336 [12:07<09:24,  3.77s/it] 56%|█████▌    | 187/336 [12:10<09:17,  3.74s/it] 56%|█████▌    | 188/336 [12:14<09:09,  3.71s/it] 56%|█████▋    | 189/336 [12:17<09:00,  3.68s/it] 57%|█████▋    | 190/336 [12:21<08:59,  3.69s/it]                                                  57%|█████▋    | 190/336 [12:21<08:59,  3.69s/it] 57%|█████▋    | 191/336 [12:25<08:54,  3.68s/it] 57%|█████▋    | 192/336 [12:28<08:46,  3.66s/it] 57%|█████▋    | 193/336 [12:32<08:43,  3.66s/it] 58%|█████▊    | 194/336 [12:36<08:42,  3.68s/it] 58%|█████▊    | 195/336 [12:39<08:34,  3.65s/it] 58%|█████▊    | 196/336 [12:43<08:38,  3.70s/it] 59%|█████▊    | 197/336 [12:47<08:35,  3.71s/it] 59%|█████▉    | 198/336 [12:51<08:45,  3.81s/it] 59%|█████▉    | 199/336 [12:55<08:38,  3.78s/it] 60%|█████▉    | 200/336 [12:58<08:28,  3.74s/it]                                                  60%|█████▉    | 200/336 [12:58<08:28,  3.74s/it][INFO|trainer.py:3512] 2024-04-07 19:42:06,858 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-04-07 19:42:06,858 >>   Num examples = 100
[INFO|trainer.py:3517] 2024-04-07 19:42:06,858 >>   Batch size = 1

  0%|          | 0/100 [00:00<?, ?it/s][A
  2%|▏         | 2/100 [00:00<00:10,  9.41it/s][A
  3%|▎         | 3/100 [00:00<00:14,  6.80it/s][A
  4%|▍         | 4/100 [00:00<00:16,  5.78it/s][A
  5%|▌         | 5/100 [00:00<00:17,  5.40it/s][A
  6%|▌         | 6/100 [00:01<00:18,  5.14it/s][A
  7%|▋         | 7/100 [00:01<00:18,  5.00it/s][A
  8%|▊         | 8/100 [00:01<00:18,  4.94it/s][A
  9%|▉         | 9/100 [00:01<00:18,  5.01it/s][A
 10%|█         | 10/100 [00:01<00:18,  4.99it/s][A
 11%|█         | 11/100 [00:02<00:17,  4.99it/s][A
 12%|█▏        | 12/100 [00:02<00:19,  4.59it/s][A
 13%|█▎        | 13/100 [00:02<00:18,  4.61it/s][A
 14%|█▍        | 14/100 [00:02<00:18,  4.66it/s][A
 15%|█▌        | 15/100 [00:02<00:18,  4.55it/s][A
 16%|█▌        | 16/100 [00:03<00:18,  4.61it/s][A
 17%|█▋        | 17/100 [00:03<00:17,  4.65it/s][A
 18%|█▊        | 18/100 [00:03<00:17,  4.68it/s][A
 19%|█▉        | 19/100 [00:03<00:17,  4.73it/s][A
 20%|██        | 20/100 [00:04<00:16,  4.86it/s][A
 21%|██        | 21/100 [00:04<00:16,  4.81it/s][A
 22%|██▏       | 22/100 [00:04<00:16,  4.77it/s][A
 23%|██▎       | 23/100 [00:04<00:16,  4.71it/s][A
 24%|██▍       | 24/100 [00:04<00:15,  4.75it/s][A
 25%|██▌       | 25/100 [00:05<00:15,  4.71it/s][A
 26%|██▌       | 26/100 [00:05<00:15,  4.81it/s][A
 27%|██▋       | 27/100 [00:05<00:15,  4.77it/s][A
 28%|██▊       | 28/100 [00:05<00:14,  4.82it/s][A
 29%|██▉       | 29/100 [00:05<00:15,  4.61it/s][A
 30%|███       | 30/100 [00:06<00:15,  4.66it/s][A
 31%|███       | 31/100 [00:06<00:15,  4.60it/s][A
 32%|███▏      | 32/100 [00:06<00:14,  4.58it/s][A
 33%|███▎      | 33/100 [00:06<00:15,  4.38it/s][A
 34%|███▍      | 34/100 [00:07<00:14,  4.50it/s][A
 35%|███▌      | 35/100 [00:07<00:14,  4.50it/s][A
 36%|███▌      | 36/100 [00:07<00:15,  4.11it/s][A
 37%|███▋      | 37/100 [00:07<00:14,  4.21it/s][A
 38%|███▊      | 38/100 [00:08<00:14,  4.26it/s][A
 39%|███▉      | 39/100 [00:08<00:13,  4.40it/s][A
 40%|████      | 40/100 [00:08<00:13,  4.56it/s][A
 41%|████      | 41/100 [00:08<00:12,  4.62it/s][A
 42%|████▏     | 42/100 [00:08<00:12,  4.62it/s][A
 43%|████▎     | 43/100 [00:09<00:12,  4.54it/s][A
 44%|████▍     | 44/100 [00:09<00:12,  4.59it/s][A
 45%|████▌     | 45/100 [00:09<00:11,  4.67it/s][A
 46%|████▌     | 46/100 [00:09<00:11,  4.67it/s][A
 47%|████▋     | 47/100 [00:09<00:11,  4.70it/s][A
 48%|████▊     | 48/100 [00:10<00:11,  4.66it/s][A
 49%|████▉     | 49/100 [00:10<00:11,  4.62it/s][A
 50%|█████     | 50/100 [00:10<00:10,  4.63it/s][A
 51%|█████     | 51/100 [00:10<00:10,  4.65it/s][A
 52%|█████▏    | 52/100 [00:11<00:10,  4.66it/s][A
 53%|█████▎    | 53/100 [00:11<00:10,  4.59it/s][A
 54%|█████▍    | 54/100 [00:11<00:09,  4.63it/s][A
 55%|█████▌    | 55/100 [00:11<00:09,  4.69it/s][A
 56%|█████▌    | 56/100 [00:11<00:09,  4.68it/s][A
 57%|█████▋    | 57/100 [00:12<00:09,  4.69it/s][A
 58%|█████▊    | 58/100 [00:12<00:08,  4.68it/s][A
 59%|█████▉    | 59/100 [00:12<00:08,  4.68it/s][A
 60%|██████    | 60/100 [00:12<00:08,  4.73it/s][A
 61%|██████    | 61/100 [00:12<00:08,  4.74it/s][A
 62%|██████▏   | 62/100 [00:13<00:08,  4.73it/s][A
 63%|██████▎   | 63/100 [00:13<00:07,  4.74it/s][A
 64%|██████▍   | 64/100 [00:13<00:07,  4.76it/s][A
 65%|██████▌   | 65/100 [00:13<00:07,  4.75it/s][A
 66%|██████▌   | 66/100 [00:14<00:07,  4.38it/s][A
 67%|██████▋   | 67/100 [00:14<00:07,  4.46it/s][A
 68%|██████▊   | 68/100 [00:14<00:07,  4.55it/s][A
 69%|██████▉   | 69/100 [00:14<00:06,  4.58it/s][A
 70%|███████   | 70/100 [00:14<00:06,  4.65it/s][A
 71%|███████   | 71/100 [00:15<00:06,  4.59it/s][A
 72%|███████▏  | 72/100 [00:15<00:06,  4.64it/s][A
 73%|███████▎  | 73/100 [00:15<00:06,  4.38it/s][A
 74%|███████▍  | 74/100 [00:15<00:05,  4.50it/s][A
 75%|███████▌  | 75/100 [00:15<00:05,  4.60it/s][A
 76%|███████▌  | 76/100 [00:16<00:05,  4.62it/s][A
 77%|███████▋  | 77/100 [00:16<00:04,  4.63it/s][A
 78%|███████▊  | 78/100 [00:16<00:04,  4.65it/s][A
 79%|███████▉  | 79/100 [00:16<00:04,  4.69it/s][A
 80%|████████  | 80/100 [00:17<00:04,  4.71it/s][A
 81%|████████  | 81/100 [00:17<00:04,  4.59it/s][A
 82%|████████▏ | 82/100 [00:17<00:03,  4.64it/s][A
 83%|████████▎ | 83/100 [00:17<00:03,  4.67it/s][A
 84%|████████▍ | 84/100 [00:17<00:03,  4.67it/s][A
 85%|████████▌ | 85/100 [00:18<00:03,  4.66it/s][A
 86%|████████▌ | 86/100 [00:18<00:02,  4.69it/s][A
 87%|████████▋ | 87/100 [00:18<00:02,  4.69it/s][A
 88%|████████▊ | 88/100 [00:18<00:02,  4.61it/s][A
 89%|████████▉ | 89/100 [00:18<00:02,  4.63it/s][A
 90%|█████████ | 90/100 [00:19<00:02,  4.65it/s][A
 91%|█████████ | 91/100 [00:19<00:01,  4.68it/s][A
 92%|█████████▏| 92/100 [00:19<00:01,  4.61it/s][A
 93%|█████████▎| 93/100 [00:19<00:01,  4.67it/s][A
 94%|█████████▍| 94/100 [00:20<00:01,  4.70it/s][A
 95%|█████████▌| 95/100 [00:20<00:01,  4.76it/s][A
 96%|█████████▌| 96/100 [00:20<00:00,  4.70it/s][A
 97%|█████████▋| 97/100 [00:20<00:00,  4.70it/s][A
 98%|█████████▊| 98/100 [00:20<00:00,  4.65it/s][A
 99%|█████████▉| 99/100 [00:21<00:00,  4.38it/s][A
100%|██████████| 100/100 [00:21<00:00,  4.25it/s][A                                                 
                                                 [A 60%|█████▉    | 200/336 [13:20<08:28,  3.74s/it]
100%|██████████| 100/100 [00:21<00:00,  4.25it/s][A
                                                 [A[INFO|trainer.py:3203] 2024-04-07 19:42:28,494 >> Saving model checkpoint to ../../saves/LLaMA2-7B/lora/01_sft/checkpoint-200
[INFO|configuration_utils.py:726] 2024-04-07 19:42:29,062 >> loading configuration file config.json from cache at /home/wenning1/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-hf/snapshots/8a0442e81540efaeb1a0fe3e95477b5e0edfd423/config.json
[INFO|configuration_utils.py:789] 2024-04-07 19:42:29,063 >> Model config LlamaConfig {
  "_name_or_path": "meta-llama/Llama-2-7b-hf",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_position_embeddings": 4096,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "float16",
  "transformers_version": "4.39.3",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|tokenization_utils_base.py:2502] 2024-04-07 19:42:29,158 >> tokenizer config file saved in ../../saves/LLaMA2-7B/lora/01_sft/checkpoint-200/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-04-07 19:42:29,158 >> Special tokens file saved in ../../saves/LLaMA2-7B/lora/01_sft/checkpoint-200/special_tokens_map.json
 60%|█████▉    | 201/336 [13:24<23:26, 10.42s/it] 60%|██████    | 202/336 [13:28<18:50,  8.44s/it] 60%|██████    | 203/336 [13:32<15:28,  6.98s/it] 61%|██████    | 204/336 [13:35<13:08,  5.97s/it] 61%|██████    | 205/336 [13:39<11:32,  5.28s/it] 61%|██████▏   | 206/336 [13:43<10:20,  4.77s/it] 62%|██████▏   | 207/336 [13:46<09:31,  4.43s/it] 62%|██████▏   | 208/336 [13:50<08:54,  4.18s/it] 62%|██████▏   | 209/336 [13:54<08:41,  4.10s/it] 62%|██████▎   | 210/336 [13:57<08:20,  3.97s/it]                                                  62%|██████▎   | 210/336 [13:57<08:20,  3.97s/it] 63%|██████▎   | 211/336 [14:01<08:08,  3.91s/it] 63%|██████▎   | 212/336 [14:05<07:55,  3.83s/it] 63%|██████▎   | 213/336 [14:09<07:52,  3.84s/it] 64%|██████▎   | 214/336 [14:13<07:46,  3.83s/it] 64%|██████▍   | 215/336 [14:16<07:39,  3.80s/it] 64%|██████▍   | 216/336 [14:20<07:29,  3.74s/it] 65%|██████▍   | 217/336 [14:24<07:25,  3.75s/it] 65%|██████▍   | 218/336 [14:27<07:16,  3.70s/it] 65%|██████▌   | 219/336 [14:31<07:14,  3.71s/it] 65%|██████▌   | 220/336 [14:35<07:13,  3.74s/it]                                                  65%|██████▌   | 220/336 [14:35<07:13,  3.74s/it] 66%|██████▌   | 221/336 [14:38<07:07,  3.72s/it] 66%|██████▌   | 222/336 [14:42<07:07,  3.75s/it] 66%|██████▋   | 223/336 [14:46<06:59,  3.72s/it] 67%|██████▋   | 224/336 [14:50<06:53,  3.69s/it] 67%|██████▋   | 225/336 [14:53<06:52,  3.71s/it] 67%|██████▋   | 226/336 [14:57<06:46,  3.69s/it] 68%|██████▊   | 227/336 [15:01<06:46,  3.73s/it] 68%|██████▊   | 228/336 [15:05<06:45,  3.75s/it] 68%|██████▊   | 229/336 [15:08<06:45,  3.79s/it] 68%|██████▊   | 230/336 [15:12<06:37,  3.75s/it]                                                  68%|██████▊   | 230/336 [15:12<06:37,  3.75s/it] 69%|██████▉   | 231/336 [15:16<06:35,  3.76s/it] 69%|██████▉   | 232/336 [15:20<06:28,  3.74s/it] 69%|██████▉   | 233/336 [15:23<06:22,  3.72s/it] 70%|██████▉   | 234/336 [15:27<06:18,  3.71s/it] 70%|██████▉   | 235/336 [15:31<06:17,  3.73s/it] 70%|███████   | 236/336 [15:34<06:11,  3.72s/it] 71%|███████   | 237/336 [15:38<06:05,  3.70s/it] 71%|███████   | 238/336 [15:42<06:03,  3.71s/it] 71%|███████   | 239/336 [15:45<05:50,  3.62s/it] 71%|███████▏  | 240/336 [15:49<05:45,  3.60s/it]                                                  71%|███████▏  | 240/336 [15:49<05:45,  3.60s/it] 72%|███████▏  | 241/336 [15:53<05:47,  3.66s/it] 72%|███████▏  | 242/336 [15:56<05:49,  3.71s/it] 72%|███████▏  | 243/336 [16:00<05:42,  3.68s/it] 73%|███████▎  | 244/336 [16:04<05:37,  3.66s/it] 73%|███████▎  | 245/336 [16:07<05:37,  3.71s/it] 73%|███████▎  | 246/336 [16:11<05:40,  3.78s/it] 74%|███████▎  | 247/336 [16:15<05:33,  3.74s/it] 74%|███████▍  | 248/336 [16:19<05:26,  3.71s/it] 74%|███████▍  | 249/336 [16:22<05:19,  3.68s/it] 74%|███████▍  | 250/336 [16:26<05:18,  3.70s/it]                                                  74%|███████▍  | 250/336 [16:26<05:18,  3.70s/it] 75%|███████▍  | 251/336 [16:30<05:16,  3.72s/it] 75%|███████▌  | 252/336 [16:34<05:12,  3.72s/it] 75%|███████▌  | 253/336 [16:37<05:10,  3.74s/it] 76%|███████▌  | 254/336 [16:41<05:04,  3.71s/it] 76%|███████▌  | 255/336 [16:45<04:57,  3.67s/it] 76%|███████▌  | 256/336 [16:48<04:59,  3.74s/it] 76%|███████▋  | 257/336 [16:52<04:55,  3.75s/it] 77%|███████▋  | 258/336 [16:56<04:48,  3.70s/it] 77%|███████▋  | 259/336 [16:59<04:44,  3.69s/it] 77%|███████▋  | 260/336 [17:03<04:37,  3.65s/it]                                                  77%|███████▋  | 260/336 [17:03<04:37,  3.65s/it] 78%|███████▊  | 261/336 [17:07<04:34,  3.65s/it] 78%|███████▊  | 262/336 [17:10<04:31,  3.67s/it] 78%|███████▊  | 263/336 [17:14<04:28,  3.68s/it] 79%|███████▊  | 264/336 [17:18<04:25,  3.69s/it] 79%|███████▉  | 265/336 [17:21<04:21,  3.68s/it] 79%|███████▉  | 266/336 [17:25<04:18,  3.70s/it] 79%|███████▉  | 267/336 [17:29<04:16,  3.72s/it] 80%|███████▉  | 268/336 [17:33<04:11,  3.70s/it] 80%|████████  | 269/336 [17:36<04:06,  3.67s/it] 80%|████████  | 270/336 [17:40<04:03,  3.69s/it]                                                  80%|████████  | 270/336 [17:40<04:03,  3.69s/it] 81%|████████  | 271/336 [17:44<03:56,  3.64s/it] 81%|████████  | 272/336 [17:47<03:55,  3.68s/it] 81%|████████▏ | 273/336 [17:51<03:49,  3.65s/it] 82%|████████▏ | 274/336 [17:55<03:48,  3.69s/it] 82%|████████▏ | 275/336 [17:59<03:49,  3.76s/it] 82%|████████▏ | 276/336 [18:02<03:42,  3.70s/it] 82%|████████▏ | 277/336 [18:06<03:36,  3.67s/it] 83%|████████▎ | 278/336 [18:10<03:35,  3.72s/it] 83%|████████▎ | 279/336 [18:13<03:30,  3.70s/it] 83%|████████▎ | 280/336 [18:17<03:33,  3.82s/it]                                                  83%|████████▎ | 280/336 [18:17<03:33,  3.82s/it] 84%|████████▎ | 281/336 [18:21<03:28,  3.79s/it] 84%|████████▍ | 282/336 [18:25<03:22,  3.76s/it] 84%|████████▍ | 283/336 [18:28<03:17,  3.72s/it] 85%|████████▍ | 284/336 [18:32<03:12,  3.70s/it] 85%|████████▍ | 285/336 [18:36<03:09,  3.71s/it] 85%|████████▌ | 286/336 [18:39<03:04,  3.69s/it] 85%|████████▌ | 287/336 [18:43<03:00,  3.68s/it] 86%|████████▌ | 288/336 [18:47<02:54,  3.64s/it] 86%|████████▌ | 289/336 [18:50<02:53,  3.70s/it] 86%|████████▋ | 290/336 [18:54<02:49,  3.68s/it]                                                  86%|████████▋ | 290/336 [18:54<02:49,  3.68s/it] 87%|████████▋ | 291/336 [18:58<02:48,  3.75s/it] 87%|████████▋ | 292/336 [19:02<02:45,  3.76s/it] 87%|████████▋ | 293/336 [19:05<02:39,  3.71s/it] 88%|████████▊ | 294/336 [19:09<02:39,  3.79s/it] 88%|████████▊ | 295/336 [19:13<02:34,  3.77s/it] 88%|████████▊ | 296/336 [19:17<02:31,  3.78s/it] 88%|████████▊ | 297/336 [19:20<02:25,  3.72s/it] 89%|████████▊ | 298/336 [19:24<02:20,  3.70s/it] 89%|████████▉ | 299/336 [19:28<02:16,  3.69s/it] 89%|████████▉ | 300/336 [19:31<02:12,  3.69s/it]                                                  89%|████████▉ | 300/336 [19:31<02:12,  3.69s/it][INFO|trainer.py:3512] 2024-04-07 19:48:39,938 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-04-07 19:48:39,938 >>   Num examples = 100
[INFO|trainer.py:3517] 2024-04-07 19:48:39,938 >>   Batch size = 1

  0%|          | 0/100 [00:00<?, ?it/s][A
  2%|▏         | 2/100 [00:00<00:10,  9.19it/s][A
  3%|▎         | 3/100 [00:00<00:14,  6.48it/s][A
  4%|▍         | 4/100 [00:00<00:16,  5.70it/s][A
  5%|▌         | 5/100 [00:00<00:17,  5.36it/s][A
  6%|▌         | 6/100 [00:01<00:18,  5.12it/s][A
  7%|▋         | 7/100 [00:01<00:18,  4.95it/s][A
  8%|▊         | 8/100 [00:01<00:18,  4.90it/s][A
  9%|▉         | 9/100 [00:01<00:18,  4.95it/s][A
 10%|█         | 10/100 [00:01<00:18,  4.81it/s][A
 11%|█         | 11/100 [00:02<00:18,  4.80it/s][A
 12%|█▏        | 12/100 [00:02<00:19,  4.50it/s][A
 13%|█▎        | 13/100 [00:02<00:19,  4.57it/s][A
 14%|█▍        | 14/100 [00:02<00:19,  4.40it/s][A
 15%|█▌        | 15/100 [00:03<00:18,  4.50it/s][A
 16%|█▌        | 16/100 [00:03<00:18,  4.58it/s][A
 17%|█▋        | 17/100 [00:03<00:18,  4.55it/s][A
 18%|█▊        | 18/100 [00:03<00:17,  4.64it/s][A
 19%|█▉        | 19/100 [00:03<00:16,  4.78it/s][A
 20%|██        | 20/100 [00:04<00:16,  4.92it/s][A
 21%|██        | 21/100 [00:04<00:16,  4.66it/s][A
 22%|██▏       | 22/100 [00:04<00:16,  4.66it/s][A
 23%|██▎       | 23/100 [00:04<00:16,  4.75it/s][A
 24%|██▍       | 24/100 [00:04<00:15,  4.84it/s][A
 25%|██▌       | 25/100 [00:05<00:15,  4.85it/s][A
 26%|██▌       | 26/100 [00:05<00:14,  4.96it/s][A
 27%|██▋       | 27/100 [00:05<00:14,  4.87it/s][A
 28%|██▊       | 28/100 [00:05<00:14,  4.90it/s][A
 29%|██▉       | 29/100 [00:05<00:14,  4.85it/s][A
 30%|███       | 30/100 [00:06<00:14,  4.82it/s][A
 31%|███       | 31/100 [00:06<00:14,  4.77it/s][A
 32%|███▏      | 32/100 [00:06<00:14,  4.68it/s][A
 33%|███▎      | 33/100 [00:06<00:15,  4.42it/s][A
 34%|███▍      | 34/100 [00:07<00:14,  4.55it/s][A
 35%|███▌      | 35/100 [00:07<00:14,  4.63it/s][A
 36%|███▌      | 36/100 [00:07<00:14,  4.33it/s][A
 37%|███▋      | 37/100 [00:07<00:14,  4.45it/s][A
 38%|███▊      | 38/100 [00:07<00:13,  4.52it/s][A
 39%|███▉      | 39/100 [00:08<00:13,  4.60it/s][A
 40%|████      | 40/100 [00:08<00:12,  4.68it/s][A
 41%|████      | 41/100 [00:08<00:12,  4.71it/s][A
 42%|████▏     | 42/100 [00:08<00:12,  4.67it/s][A
 43%|████▎     | 43/100 [00:09<00:12,  4.66it/s][A
 44%|████▍     | 44/100 [00:09<00:12,  4.65it/s][A
 45%|████▌     | 45/100 [00:09<00:11,  4.73it/s][A
 46%|████▌     | 46/100 [00:09<00:11,  4.70it/s][A
 47%|████▋     | 47/100 [00:09<00:11,  4.71it/s][A
 48%|████▊     | 48/100 [00:10<00:11,  4.71it/s][A
 49%|████▉     | 49/100 [00:10<00:10,  4.74it/s][A
 50%|█████     | 50/100 [00:10<00:10,  4.75it/s][A
 51%|█████     | 51/100 [00:10<00:10,  4.74it/s][A
 52%|█████▏    | 52/100 [00:10<00:10,  4.68it/s][A
 53%|█████▎    | 53/100 [00:11<00:10,  4.64it/s][A
 54%|█████▍    | 54/100 [00:11<00:09,  4.68it/s][A
 55%|█████▌    | 55/100 [00:11<00:09,  4.68it/s][A
 56%|█████▌    | 56/100 [00:11<00:09,  4.66it/s][A
 57%|█████▋    | 57/100 [00:11<00:09,  4.70it/s][A
 58%|█████▊    | 58/100 [00:12<00:09,  4.63it/s][A
 59%|█████▉    | 59/100 [00:12<00:08,  4.64it/s][A
 60%|██████    | 60/100 [00:12<00:08,  4.67it/s][A
 61%|██████    | 61/100 [00:12<00:08,  4.67it/s][A
 62%|██████▏   | 62/100 [00:13<00:08,  4.70it/s][A
 63%|██████▎   | 63/100 [00:13<00:07,  4.75it/s][A
 64%|██████▍   | 64/100 [00:13<00:07,  4.74it/s][A
 65%|██████▌   | 65/100 [00:13<00:07,  4.72it/s][A
 66%|██████▌   | 66/100 [00:13<00:07,  4.42it/s][A
 67%|██████▋   | 67/100 [00:14<00:07,  4.48it/s][A
 68%|██████▊   | 68/100 [00:14<00:07,  4.55it/s][A
 69%|██████▉   | 69/100 [00:14<00:06,  4.58it/s][A
 70%|███████   | 70/100 [00:14<00:06,  4.57it/s][A
 71%|███████   | 71/100 [00:15<00:06,  4.56it/s][A
 72%|███████▏  | 72/100 [00:15<00:06,  4.62it/s][A
 73%|███████▎  | 73/100 [00:15<00:06,  4.37it/s][A
 74%|███████▍  | 74/100 [00:15<00:05,  4.48it/s][A
 75%|███████▌  | 75/100 [00:15<00:05,  4.58it/s][A
 76%|███████▌  | 76/100 [00:16<00:05,  4.64it/s][A
 77%|███████▋  | 77/100 [00:16<00:04,  4.62it/s][A
 78%|███████▊  | 78/100 [00:16<00:04,  4.59it/s][A
 79%|███████▉  | 79/100 [00:16<00:04,  4.62it/s][A
 80%|████████  | 80/100 [00:16<00:04,  4.67it/s][A
 81%|████████  | 81/100 [00:17<00:04,  4.61it/s][A
 82%|████████▏ | 82/100 [00:17<00:03,  4.67it/s][A
 83%|████████▎ | 83/100 [00:17<00:03,  4.69it/s][A
 84%|████████▍ | 84/100 [00:17<00:03,  4.73it/s][A
 85%|████████▌ | 85/100 [00:18<00:03,  4.73it/s][A
 86%|████████▌ | 86/100 [00:18<00:02,  4.71it/s][A
 87%|████████▋ | 87/100 [00:18<00:02,  4.71it/s][A
 88%|████████▊ | 88/100 [00:18<00:02,  4.74it/s][A
 89%|████████▉ | 89/100 [00:18<00:02,  4.66it/s][A
 90%|█████████ | 90/100 [00:19<00:02,  4.67it/s][A
 91%|█████████ | 91/100 [00:19<00:01,  4.65it/s][A
 92%|█████████▏| 92/100 [00:19<00:01,  4.61it/s][A
 93%|█████████▎| 93/100 [00:19<00:01,  4.67it/s][A
 94%|█████████▍| 94/100 [00:19<00:01,  4.68it/s][A
 95%|█████████▌| 95/100 [00:20<00:01,  4.70it/s][A
 96%|█████████▌| 96/100 [00:20<00:00,  4.65it/s][A
 97%|█████████▋| 97/100 [00:20<00:00,  4.72it/s][A
 98%|█████████▊| 98/100 [00:20<00:00,  4.67it/s][A
 99%|█████████▉| 99/100 [00:21<00:00,  4.40it/s][A
100%|██████████| 100/100 [00:21<00:00,  4.24it/s][A                                                 
                                                 [A 89%|████████▉ | 300/336 [19:53<02:12,  3.69s/it]
100%|██████████| 100/100 [00:21<00:00,  4.24it/s][A
                                                 [A[INFO|trainer.py:3203] 2024-04-07 19:49:01,496 >> Saving model checkpoint to ../../saves/LLaMA2-7B/lora/01_sft/checkpoint-300
[INFO|configuration_utils.py:726] 2024-04-07 19:49:02,415 >> loading configuration file config.json from cache at /home/wenning1/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-hf/snapshots/8a0442e81540efaeb1a0fe3e95477b5e0edfd423/config.json
[INFO|configuration_utils.py:789] 2024-04-07 19:49:02,416 >> Model config LlamaConfig {
  "_name_or_path": "meta-llama/Llama-2-7b-hf",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_position_embeddings": 4096,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "float16",
  "transformers_version": "4.39.3",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|tokenization_utils_base.py:2502] 2024-04-07 19:49:02,528 >> tokenizer config file saved in ../../saves/LLaMA2-7B/lora/01_sft/checkpoint-300/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-04-07 19:49:02,528 >> Special tokens file saved in ../../saves/LLaMA2-7B/lora/01_sft/checkpoint-300/special_tokens_map.json
 90%|████████▉ | 301/336 [19:58<06:06, 10.48s/it] 90%|████████▉ | 302/336 [20:01<04:46,  8.42s/it] 90%|█████████ | 303/336 [20:05<03:50,  6.99s/it] 90%|█████████ | 304/336 [20:09<03:13,  6.05s/it] 91%|█████████ | 305/336 [20:13<02:45,  5.34s/it] 91%|█████████ | 306/336 [20:16<02:24,  4.83s/it] 91%|█████████▏| 307/336 [20:20<02:10,  4.52s/it] 92%|█████████▏| 308/336 [20:24<01:59,  4.27s/it] 92%|█████████▏| 309/336 [20:27<01:50,  4.11s/it] 92%|█████████▏| 310/336 [20:31<01:43,  3.98s/it]                                                  92%|█████████▏| 310/336 [20:31<01:43,  3.98s/it] 93%|█████████▎| 311/336 [20:35<01:36,  3.87s/it] 93%|█████████▎| 312/336 [20:39<01:32,  3.86s/it] 93%|█████████▎| 313/336 [20:42<01:26,  3.78s/it] 93%|█████████▎| 314/336 [20:46<01:23,  3.79s/it] 94%|█████████▍| 315/336 [20:50<01:18,  3.74s/it] 94%|█████████▍| 316/336 [20:53<01:14,  3.71s/it] 94%|█████████▍| 317/336 [20:57<01:09,  3.67s/it] 95%|█████████▍| 318/336 [21:00<01:05,  3.66s/it] 95%|█████████▍| 319/336 [21:04<01:02,  3.65s/it] 95%|█████████▌| 320/336 [21:08<00:58,  3.65s/it]                                                  95%|█████████▌| 320/336 [21:08<00:58,  3.65s/it] 96%|█████████▌| 321/336 [21:11<00:54,  3.64s/it] 96%|█████████▌| 322/336 [21:15<00:50,  3.62s/it] 96%|█████████▌| 323/336 [21:19<00:47,  3.66s/it] 96%|█████████▋| 324/336 [21:22<00:43,  3.66s/it] 97%|█████████▋| 325/336 [21:26<00:41,  3.76s/it] 97%|█████████▋| 326/336 [21:30<00:37,  3.76s/it] 97%|█████████▋| 327/336 [21:34<00:34,  3.78s/it] 98%|█████████▊| 328/336 [21:38<00:29,  3.73s/it] 98%|█████████▊| 329/336 [21:41<00:26,  3.79s/it] 98%|█████████▊| 330/336 [21:45<00:22,  3.75s/it]                                                  98%|█████████▊| 330/336 [21:45<00:22,  3.75s/it] 99%|█████████▊| 331/336 [21:49<00:18,  3.80s/it] 99%|█████████▉| 332/336 [21:53<00:15,  3.83s/it] 99%|█████████▉| 333/336 [21:57<00:11,  3.78s/it] 99%|█████████▉| 334/336 [22:00<00:07,  3.74s/it]100%|█████████▉| 335/336 [22:04<00:03,  3.75s/it]100%|██████████| 336/336 [22:08<00:00,  3.73s/it][INFO|trainer.py:2231] 2024-04-07 19:51:16,159 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


[INFO|trainer.py:2436] 2024-04-07 19:51:16,159 >> Loading best model from ../../saves/LLaMA2-7B/lora/01_sft/checkpoint-300 (score: 0.25546151399612427).
                                                 100%|██████████| 336/336 [22:08<00:00,  3.73s/it]100%|██████████| 336/336 [22:08<00:00,  3.95s/it]
[INFO|trainer.py:3203] 2024-04-07 19:51:16,203 >> Saving model checkpoint to ../../saves/LLaMA2-7B/lora/01_sft
[INFO|configuration_utils.py:726] 2024-04-07 19:51:16,665 >> loading configuration file config.json from cache at /home/wenning1/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-hf/snapshots/8a0442e81540efaeb1a0fe3e95477b5e0edfd423/config.json
[INFO|configuration_utils.py:789] 2024-04-07 19:51:16,667 >> Model config LlamaConfig {
  "_name_or_path": "meta-llama/Llama-2-7b-hf",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_position_embeddings": 4096,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "float16",
  "transformers_version": "4.39.3",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|tokenization_utils_base.py:2502] 2024-04-07 19:51:16,786 >> tokenizer config file saved in ../../saves/LLaMA2-7B/lora/01_sft/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-04-07 19:51:16,786 >> Special tokens file saved in ../../saves/LLaMA2-7B/lora/01_sft/special_tokens_map.json
[INFO|trainer.py:3512] 2024-04-07 19:51:30,084 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-04-07 19:51:30,084 >>   Num examples = 100
[INFO|trainer.py:3517] 2024-04-07 19:51:30,084 >>   Batch size = 1
  0%|          | 0/100 [00:00<?, ?it/s]  2%|▏         | 2/100 [00:00<00:10,  9.00it/s]  3%|▎         | 3/100 [00:00<00:15,  6.30it/s]  4%|▍         | 4/100 [00:00<00:17,  5.60it/s]  5%|▌         | 5/100 [00:00<00:18,  5.28it/s]  6%|▌         | 6/100 [00:01<00:18,  5.01it/s]  7%|▋         | 7/100 [00:01<00:19,  4.87it/s]  8%|▊         | 8/100 [00:01<00:19,  4.81it/s]  9%|▉         | 9/100 [00:01<00:19,  4.77it/s] 10%|█         | 10/100 [00:01<00:18,  4.76it/s] 11%|█         | 11/100 [00:02<00:18,  4.82it/s] 12%|█▏        | 12/100 [00:02<00:19,  4.47it/s] 13%|█▎        | 13/100 [00:02<00:19,  4.56it/s] 14%|█▍        | 14/100 [00:02<00:18,  4.59it/s] 15%|█▌        | 15/100 [00:03<00:18,  4.61it/s] 16%|█▌        | 16/100 [00:03<00:18,  4.54it/s] 17%|█▋        | 17/100 [00:03<00:18,  4.59it/s] 18%|█▊        | 18/100 [00:03<00:17,  4.65it/s] 19%|█▉        | 19/100 [00:03<00:17,  4.73it/s] 20%|██        | 20/100 [00:04<00:16,  4.80it/s] 21%|██        | 21/100 [00:04<00:16,  4.73it/s] 22%|██▏       | 22/100 [00:04<00:16,  4.71it/s] 23%|██▎       | 23/100 [00:04<00:16,  4.71it/s] 24%|██▍       | 24/100 [00:04<00:15,  4.78it/s] 25%|██▌       | 25/100 [00:05<00:15,  4.79it/s] 26%|██▌       | 26/100 [00:05<00:15,  4.84it/s] 27%|██▋       | 27/100 [00:05<00:15,  4.72it/s] 28%|██▊       | 28/100 [00:05<00:15,  4.78it/s] 29%|██▉       | 29/100 [00:05<00:14,  4.79it/s] 30%|███       | 30/100 [00:06<00:14,  4.79it/s] 31%|███       | 31/100 [00:06<00:14,  4.73it/s] 32%|███▏      | 32/100 [00:06<00:14,  4.69it/s] 33%|███▎      | 33/100 [00:06<00:15,  4.41it/s] 34%|███▍      | 34/100 [00:07<00:14,  4.47it/s] 35%|███▌      | 35/100 [00:07<00:14,  4.54it/s] 36%|███▌      | 36/100 [00:07<00:14,  4.30it/s] 37%|███▋      | 37/100 [00:07<00:14,  4.41it/s] 38%|███▊      | 38/100 [00:08<00:13,  4.49it/s] 39%|███▉      | 39/100 [00:08<00:13,  4.52it/s] 40%|████      | 40/100 [00:08<00:13,  4.59it/s] 41%|████      | 41/100 [00:08<00:12,  4.67it/s] 42%|████▏     | 42/100 [00:08<00:12,  4.61it/s] 43%|████▎     | 43/100 [00:09<00:12,  4.60it/s] 44%|████▍     | 44/100 [00:09<00:12,  4.61it/s] 45%|████▌     | 45/100 [00:09<00:11,  4.66it/s] 46%|████▌     | 46/100 [00:09<00:11,  4.72it/s] 47%|████▋     | 47/100 [00:09<00:11,  4.73it/s] 48%|████▊     | 48/100 [00:10<00:11,  4.69it/s] 49%|████▉     | 49/100 [00:10<00:10,  4.71it/s] 50%|█████     | 50/100 [00:10<00:10,  4.74it/s] 51%|█████     | 51/100 [00:10<00:10,  4.73it/s] 52%|█████▏    | 52/100 [00:10<00:10,  4.68it/s] 53%|█████▎    | 53/100 [00:11<00:10,  4.68it/s] 54%|█████▍    | 54/100 [00:11<00:09,  4.72it/s] 55%|█████▌    | 55/100 [00:11<00:09,  4.69it/s] 56%|█████▌    | 56/100 [00:11<00:09,  4.73it/s] 57%|█████▋    | 57/100 [00:12<00:09,  4.75it/s] 58%|█████▊    | 58/100 [00:12<00:08,  4.74it/s] 59%|█████▉    | 59/100 [00:12<00:08,  4.69it/s] 60%|██████    | 60/100 [00:12<00:08,  4.48it/s] 61%|██████    | 61/100 [00:12<00:08,  4.57it/s] 62%|██████▏   | 62/100 [00:13<00:08,  4.47it/s] 63%|██████▎   | 63/100 [00:13<00:08,  4.56it/s] 64%|██████▍   | 64/100 [00:13<00:07,  4.61it/s] 65%|██████▌   | 65/100 [00:13<00:07,  4.50it/s] 66%|██████▌   | 66/100 [00:14<00:07,  4.29it/s] 67%|██████▋   | 67/100 [00:14<00:07,  4.20it/s] 68%|██████▊   | 68/100 [00:14<00:07,  4.38it/s] 69%|██████▉   | 69/100 [00:14<00:06,  4.47it/s] 70%|███████   | 70/100 [00:14<00:06,  4.53it/s] 71%|███████   | 71/100 [00:15<00:06,  4.57it/s] 72%|███████▏  | 72/100 [00:15<00:06,  4.61it/s] 73%|███████▎  | 73/100 [00:15<00:06,  4.38it/s] 74%|███████▍  | 74/100 [00:15<00:05,  4.47it/s] 75%|███████▌  | 75/100 [00:16<00:05,  4.57it/s] 76%|███████▌  | 76/100 [00:16<00:05,  4.65it/s] 77%|███████▋  | 77/100 [00:16<00:04,  4.65it/s] 78%|███████▊  | 78/100 [00:16<00:04,  4.68it/s] 79%|███████▉  | 79/100 [00:16<00:04,  4.72it/s] 80%|████████  | 80/100 [00:17<00:04,  4.72it/s] 81%|████████  | 81/100 [00:17<00:04,  4.68it/s] 82%|████████▏ | 82/100 [00:17<00:03,  4.72it/s] 83%|████████▎ | 83/100 [00:17<00:03,  4.73it/s] 84%|████████▍ | 84/100 [00:17<00:03,  4.77it/s] 85%|████████▌ | 85/100 [00:18<00:03,  4.75it/s] 86%|████████▌ | 86/100 [00:18<00:02,  4.73it/s] 87%|████████▋ | 87/100 [00:18<00:02,  4.70it/s] 88%|████████▊ | 88/100 [00:18<00:02,  4.74it/s] 89%|████████▉ | 89/100 [00:19<00:02,  4.74it/s] 90%|█████████ | 90/100 [00:19<00:02,  4.64it/s] 91%|█████████ | 91/100 [00:19<00:01,  4.66it/s] 92%|█████████▏| 92/100 [00:19<00:01,  4.61it/s] 93%|█████████▎| 93/100 [00:19<00:01,  4.66it/s] 94%|█████████▍| 94/100 [00:20<00:01,  4.66it/s] 95%|█████████▌| 95/100 [00:20<00:01,  4.71it/s] 96%|█████████▌| 96/100 [00:20<00:00,  4.59it/s] 97%|█████████▋| 97/100 [00:20<00:00,  4.59it/s] 98%|█████████▊| 98/100 [00:20<00:00,  4.62it/s] 99%|█████████▉| 99/100 [00:21<00:00,  4.32it/s]100%|██████████| 100/100 [00:21<00:00,  4.21it/s]100%|██████████| 100/100 [00:21<00:00,  4.65it/s]
[INFO|modelcard.py:450] 2024-04-07 19:51:51,795 >> Dropping the following result as it does not have all the necessary fields:
{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}
