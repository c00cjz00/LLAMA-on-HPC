[2024-04-07 21:32:29,812] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
04/07/2024 21:32:31 - INFO - llmtuner.hparams.parser - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, compute dtype: torch.float16
04/07/2024 21:32:32 - INFO - llmtuner.data.template - Add pad token: </s>
04/07/2024 21:32:32 - INFO - llmtuner.data.loader - Loading dataset demo_sft.json...
input_ids:
[887, 526, 263, 8444, 319, 29902, 20255, 4240, 491, 405, 3210, 29907, 29889, 450, 1404, 366, 526, 19912, 7726, 29879, 18375, 3245, 10013, 322, 5304, 515, 27807, 29889, 13, 12968, 29901, 29871, 30446, 232, 136, 149, 235, 133, 168, 235, 134, 153, 31480, 30908, 235, 172, 181, 30847, 31502, 31032, 234, 156, 133, 13, 30647, 232, 178, 185, 232, 178, 185, 30214, 232, 140, 158, 29955, 233, 176, 181, 30214, 236, 131, 156, 30287, 30470, 30214, 232, 178, 162, 235, 169, 189, 30780, 30214, 30672, 30613, 232, 176, 172, 30319, 31687, 30429, 235, 133, 140, 232, 193, 139, 30923, 30214, 31325, 231, 187, 151, 30214, 31855, 31180, 31838, 31190, 30210, 30257, 30214, 30606, 30974, 30769, 30413, 31823, 233, 176, 164, 232, 147, 134, 31475, 234, 145, 172, 30214, 235, 174, 142, 232, 152, 146, 30383, 30446, 232, 136, 149, 235, 133, 168, 235, 134, 153, 31480, 30908, 235, 172, 181, 30847, 31502, 31032, 234, 156, 133, 30267, 13, 7900, 22137, 29901, 29871, 29871, 232, 176, 172, 30319, 30544, 31928, 235, 133, 168, 235, 134, 153, 234, 154, 138, 30210, 30993, 233, 182, 132, 30267, 30613, 30899, 30698, 236, 131, 146, 236, 132, 145, 232, 176, 172, 30319, 236, 132, 142, 31134, 30503, 31863, 31577, 30210, 236, 166, 181, 31855, 231, 193, 137, 234, 186, 172, 31201, 31221, 30210, 234, 154, 138, 234, 142, 131, 30214, 30682, 30651, 31244, 235, 177, 150, 31221, 232, 132, 157, 30287, 31959, 30417, 233, 179, 170, 236, 132, 142, 31124, 30214, 31419, 30847, 233, 136, 165, 235, 186, 148, 30214, 234, 139, 175, 232, 160, 164, 30214, 233, 187, 187, 233, 182, 182, 31184, 30214, 231, 187, 169, 231, 187, 151, 236, 166, 181, 31855, 30429, 232, 176, 172, 30319, 30923, 232, 147, 134, 31995, 234, 150, 159, 30214, 235, 134, 164, 235, 155, 194, 235, 151, 151, 30214, 235, 146, 163, 31854, 31184, 30214, 234, 169, 132, 31981, 232, 176, 172, 30319, 232, 147, 134, 30287, 31959, 233, 181, 188, 234, 133, 187, 31855, 31399, 30503, 231, 188, 193, 30801, 236, 164, 161, 31855, 30834, 30214, 236, 131, 156, 31959, 30769, 30392, 231, 188, 193, 234, 137, 180, 31180, 30528, 235, 135, 133, 235, 133, 173, 30210, 31855, 30834, 30214, 31325, 231, 187, 151, 30413, 30698, 235, 177, 150, 232, 176, 172, 30319, 234, 187, 192, 30392, 232, 147, 134, 31366, 31238, 235, 189, 189, 30505, 232, 189, 141, 30429, 30413, 31124, 30214, 30613, 30899, 30505, 31032, 234, 156, 133, 30446, 232, 136, 149, 235, 133, 168, 235, 134, 153, 31117, 31069, 30847, 30801, 232, 176, 172, 30319, 30993, 233, 182, 132, 232, 157, 183, 30908, 31238, 30698, 31436, 30974, 31475, 236, 137, 174, 30963, 30505, 236, 137, 174, 30486, 30210, 31084, 232, 179, 145, 30557, 234, 184, 169, 232, 176, 172, 30319, 31032, 234, 156, 133, 30267, 2]
inputs:
You are a helpful AI assistant built by NCHC. The user you are helping speaks Traditional Chinese and comes from Taiwan.
 Human: 小兒肥胖超重該如何治療
女寶寶，剛7歲，這一年，察覺到，我家孩子身上肉很多，而且，食量非常的大，平時都不喜歡吃去玩，請問：小兒肥胖超重該如何治療。
Assistant:  孩子出現肥胖症的情況。家長要透過孩子運功和健康的飲食來緩解他的症狀，可以先讓他做一些有氧運動，比如慢跑，爬坡，游泳等，並且飲食上孩子多吃黃瓜，胡蘿蔔，菠菜等，禁止孩子吃一些油炸食品和乾果類食物，這些都是乾熱量高脂肪的食物，而且不要讓孩子總是吃完就躺在床上不動，家長在治療小兒肥胖期間如果孩子情況嚴重就要及時去醫院在醫生的指導下給孩子治療。</s>
label_ids:
[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 29871, 232, 176, 172, 30319, 30544, 31928, 235, 133, 168, 235, 134, 153, 234, 154, 138, 30210, 30993, 233, 182, 132, 30267, 30613, 30899, 30698, 236, 131, 146, 236, 132, 145, 232, 176, 172, 30319, 236, 132, 142, 31134, 30503, 31863, 31577, 30210, 236, 166, 181, 31855, 231, 193, 137, 234, 186, 172, 31201, 31221, 30210, 234, 154, 138, 234, 142, 131, 30214, 30682, 30651, 31244, 235, 177, 150, 31221, 232, 132, 157, 30287, 31959, 30417, 233, 179, 170, 236, 132, 142, 31124, 30214, 31419, 30847, 233, 136, 165, 235, 186, 148, 30214, 234, 139, 175, 232, 160, 164, 30214, 233, 187, 187, 233, 182, 182, 31184, 30214, 231, 187, 169, 231, 187, 151, 236, 166, 181, 31855, 30429, 232, 176, 172, 30319, 30923, 232, 147, 134, 31995, 234, 150, 159, 30214, 235, 134, 164, 235, 155, 194, 235, 151, 151, 30214, 235, 146, 163, 31854, 31184, 30214, 234, 169, 132, 31981, 232, 176, 172, 30319, 232, 147, 134, 30287, 31959, 233, 181, 188, 234, 133, 187, 31855, 31399, 30503, 231, 188, 193, 30801, 236, 164, 161, 31855, 30834, 30214, 236, 131, 156, 31959, 30769, 30392, 231, 188, 193, 234, 137, 180, 31180, 30528, 235, 135, 133, 235, 133, 173, 30210, 31855, 30834, 30214, 31325, 231, 187, 151, 30413, 30698, 235, 177, 150, 232, 176, 172, 30319, 234, 187, 192, 30392, 232, 147, 134, 31366, 31238, 235, 189, 189, 30505, 232, 189, 141, 30429, 30413, 31124, 30214, 30613, 30899, 30505, 31032, 234, 156, 133, 30446, 232, 136, 149, 235, 133, 168, 235, 134, 153, 31117, 31069, 30847, 30801, 232, 176, 172, 30319, 30993, 233, 182, 132, 232, 157, 183, 30908, 31238, 30698, 31436, 30974, 31475, 236, 137, 174, 30963, 30505, 236, 137, 174, 30486, 30210, 31084, 232, 179, 145, 30557, 234, 184, 169, 232, 176, 172, 30319, 31032, 234, 156, 133, 30267, 2]
labels:
孩子出現肥胖症的情況。家長要透過孩子運功和健康的飲食來緩解他的症狀，可以先讓他做一些有氧運動，比如慢跑，爬坡，游泳等，並且飲食上孩子多吃黃瓜，胡蘿蔔，菠菜等，禁止孩子吃一些油炸食品和乾果類食物，這些都是乾熱量高脂肪的食物，而且不要讓孩子總是吃完就躺在床上不動，家長在治療小兒肥胖期間如果孩子情況嚴重就要及時去醫院在醫生的指導下給孩子治療。</s>
04/07/2024 21:32:52 - INFO - llmtuner.model.patcher - Gradient checkpointing enabled.
04/07/2024 21:32:52 - INFO - llmtuner.model.adapter - Fine-tuning method: LoRA
04/07/2024 21:32:52 - INFO - llmtuner.model.loader - trainable params: 4194304 || all params: 6742609920 || trainable%: 0.0622
{'loss': 1.5123, 'grad_norm': 0.18152138590812683, 'learning_rate': 2.5e-05, 'epoch': 0.09}
{'loss': 1.4671, 'grad_norm': 0.23878252506256104, 'learning_rate': 5e-05, 'epoch': 0.18}
{'loss': 1.4091, 'grad_norm': 0.36483868956565857, 'learning_rate': 4.9876553763060684e-05, 'epoch': 0.27}
{'loss': 1.3319, 'grad_norm': 0.39424562454223633, 'learning_rate': 4.950743417011591e-05, 'epoch': 0.36}
{'loss': 1.2312, 'grad_norm': 0.46922221779823303, 'learning_rate': 4.889628653514402e-05, 'epoch': 0.44}
{'loss': 1.0808, 'grad_norm': 0.6028842329978943, 'learning_rate': 4.804914636820517e-05, 'epoch': 0.53}
{'loss': 0.937, 'grad_norm': 0.7797450423240662, 'learning_rate': 4.6974379770560846e-05, 'epoch': 0.62}
{'loss': 0.9074, 'grad_norm': 0.8062946796417236, 'learning_rate': 4.5682600813576435e-05, 'epoch': 0.71}
{'loss': 0.8172, 'grad_norm': 0.903231680393219, 'learning_rate': 4.41865667173477e-05, 'epoch': 0.8}
{'loss': 0.7035, 'grad_norm': 1.1552540063858032, 'learning_rate': 4.2501051864235636e-05, 'epoch': 0.89}
{'eval_loss': 0.6518945097923279, 'eval_runtime': 21.1298, 'eval_samples_per_second': 4.733, 'eval_steps_per_second': 4.733, 'epoch': 0.89}
{'loss': 0.6473, 'grad_norm': 1.0911840200424194, 'learning_rate': 4.0642701891514e-05, 'epoch': 0.98}
{'loss': 0.6072, 'grad_norm': 1.3202534914016724, 'learning_rate': 3.862986930406669e-05, 'epoch': 1.07}
{'loss': 0.5207, 'grad_norm': 1.5197944641113281, 'learning_rate': 3.6482432230574446e-05, 'epoch': 1.16}
{'loss': 0.5031, 'grad_norm': 1.1826415061950684, 'learning_rate': 3.4221598113100195e-05, 'epoch': 1.24}
{'loss': 0.4015, 'grad_norm': 1.3442968130111694, 'learning_rate': 3.186969426877563e-05, 'epoch': 1.33}
{'loss': 0.4254, 'grad_norm': 1.3303608894348145, 'learning_rate': 2.9449947391938766e-05, 'epoch': 1.42}
{'loss': 0.397, 'grad_norm': 1.6538068056106567, 'learning_rate': 2.6986254174292862e-05, 'epoch': 1.51}
{'loss': 0.3403, 'grad_norm': 1.185550332069397, 'learning_rate': 2.4502945308373246e-05, 'epoch': 1.6}
{'loss': 0.3312, 'grad_norm': 1.3532568216323853, 'learning_rate': 2.2024545204952383e-05, 'epoch': 1.69}
{'loss': 0.2934, 'grad_norm': 1.4723566770553589, 'learning_rate': 1.957552979734205e-05, 'epoch': 1.78}
{'eval_loss': 0.30046704411506653, 'eval_runtime': 21.0924, 'eval_samples_per_second': 4.741, 'eval_steps_per_second': 4.741, 'epoch': 1.78}
{'loss': 0.3557, 'grad_norm': 1.49557363986969, 'learning_rate': 1.7180084824444325e-05, 'epoch': 1.87}
{'loss': 0.3166, 'grad_norm': 1.2402687072753906, 'learning_rate': 1.4861866979675154e-05, 'epoch': 1.96}
{'loss': 0.2557, 'grad_norm': 1.2528328895568848, 'learning_rate': 1.2643770284581929e-05, 'epoch': 2.04}
{'loss': 0.3253, 'grad_norm': 1.7661855220794678, 'learning_rate': 1.0547699994378787e-05, 'epoch': 2.13}
{'loss': 0.3528, 'grad_norm': 1.178420901298523, 'learning_rate': 8.594356268240616e-06, 'epoch': 2.22}
{'loss': 0.333, 'grad_norm': 1.3704043626785278, 'learning_rate': 6.803029740762648e-06, 'epoch': 2.31}
{'loss': 0.2908, 'grad_norm': 1.1682370901107788, 'learning_rate': 5.191411013460645e-06, 'epoch': 2.4}
{'loss': 0.3097, 'grad_norm': 1.1617571115493774, 'learning_rate': 3.775415947715899e-06, 'epoch': 2.49}
{'loss': 0.215, 'grad_norm': 1.1929434537887573, 'learning_rate': 2.5690284845196923e-06, 'epoch': 2.58}
{'loss': 0.2219, 'grad_norm': 1.180185317993164, 'learning_rate': 1.5841625432818057e-06, 'epoch': 2.67}
{'eval_loss': 0.25560736656188965, 'eval_runtime': 21.1624, 'eval_samples_per_second': 4.725, 'eval_steps_per_second': 4.725, 'epoch': 2.67}
{'loss': 0.2376, 'grad_norm': 1.0424257516860962, 'learning_rate': 8.305443635490711e-07, 'epoch': 2.76}
{'loss': 0.2647, 'grad_norm': 1.297963261604309, 'learning_rate': 3.1561645159166597e-07, 'epoch': 2.84}
{'loss': 0.2969, 'grad_norm': 1.2583056688308716, 'learning_rate': 4.4464080451675494e-08, 'epoch': 2.93}
{'train_runtime': 1334.3176, 'train_samples_per_second': 2.024, 'train_steps_per_second': 0.252, 'train_loss': 0.5885577294088545, 'epoch': 2.99}
***** train metrics *****
  epoch                    =       2.99
  train_loss               =     0.5886
  train_runtime            = 0:22:14.31
  train_samples_per_second =      2.024
  train_steps_per_second   =      0.252
Figure saved at: ../../saves/LLaMA2-7B/lora/sft/training_loss.png
Figure saved at: ../../saves/LLaMA2-7B/lora/sft/training_eval_loss.png
***** eval metrics *****
  epoch                   =       2.99
  eval_loss               =     0.2556
  eval_runtime            = 0:00:21.03
  eval_samples_per_second =      4.753
  eval_steps_per_second   =      4.753
