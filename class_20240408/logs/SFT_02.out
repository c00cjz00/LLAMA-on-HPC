[2024-04-07 19:28:42,756] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
04/07/2024 19:28:44 - WARNING - llmtuner.hparams.parser - We recommend enable `upcast_layernorm` in quantized training.
04/07/2024 19:28:44 - INFO - llmtuner.hparams.parser - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, compute dtype: torch.float16
04/07/2024 19:28:45 - INFO - llmtuner.data.template - Add pad token: </s>
04/07/2024 19:28:45 - INFO - llmtuner.data.loader - Loading dataset demo_sft.json...
input_ids:
[887, 526, 263, 8444, 319, 29902, 20255, 4240, 491, 405, 3210, 29907, 29889, 450, 1404, 366, 526, 19912, 7726, 29879, 18375, 3245, 10013, 322, 5304, 515, 27807, 29889, 13, 12968, 29901, 29871, 30446, 232, 136, 149, 235, 133, 168, 235, 134, 153, 31480, 30908, 235, 172, 181, 30847, 31502, 31032, 234, 156, 133, 13, 30647, 232, 178, 185, 232, 178, 185, 30214, 232, 140, 158, 29955, 233, 176, 181, 30214, 236, 131, 156, 30287, 30470, 30214, 232, 178, 162, 235, 169, 189, 30780, 30214, 30672, 30613, 232, 176, 172, 30319, 31687, 30429, 235, 133, 140, 232, 193, 139, 30923, 30214, 31325, 231, 187, 151, 30214, 31855, 31180, 31838, 31190, 30210, 30257, 30214, 30606, 30974, 30769, 30413, 31823, 233, 176, 164, 232, 147, 134, 31475, 234, 145, 172, 30214, 235, 174, 142, 232, 152, 146, 30383, 30446, 232, 136, 149, 235, 133, 168, 235, 134, 153, 31480, 30908, 235, 172, 181, 30847, 31502, 31032, 234, 156, 133, 30267, 13, 7900, 22137, 29901, 29871, 29871, 232, 176, 172, 30319, 30544, 31928, 235, 133, 168, 235, 134, 153, 234, 154, 138, 30210, 30993, 233, 182, 132, 30267, 30613, 30899, 30698, 236, 131, 146, 236, 132, 145, 232, 176, 172, 30319, 236, 132, 142, 31134, 30503, 31863, 31577, 30210, 236, 166, 181, 31855, 231, 193, 137, 234, 186, 172, 31201, 31221, 30210, 234, 154, 138, 234, 142, 131, 30214, 30682, 30651, 31244, 235, 177, 150, 31221, 232, 132, 157, 30287, 31959, 30417, 233, 179, 170, 236, 132, 142, 31124, 30214, 31419, 30847, 233, 136, 165, 235, 186, 148, 30214, 234, 139, 175, 232, 160, 164, 30214, 233, 187, 187, 233, 182, 182, 31184, 30214, 231, 187, 169, 231, 187, 151, 236, 166, 181, 31855, 30429, 232, 176, 172, 30319, 30923, 232, 147, 134, 31995, 234, 150, 159, 30214, 235, 134, 164, 235, 155, 194, 235, 151, 151, 30214, 235, 146, 163, 31854, 31184, 30214, 234, 169, 132, 31981, 232, 176, 172, 30319, 232, 147, 134, 30287, 31959, 233, 181, 188, 234, 133, 187, 31855, 31399, 30503, 231, 188, 193, 30801, 236, 164, 161, 31855, 30834, 30214, 236, 131, 156, 31959, 30769, 30392, 231, 188, 193, 234, 137, 180, 31180, 30528, 235, 135, 133, 235, 133, 173, 30210, 31855, 30834, 30214, 31325, 231, 187, 151, 30413, 30698, 235, 177, 150, 232, 176, 172, 30319, 234, 187, 192, 30392, 232, 147, 134, 31366, 31238, 235, 189, 189, 30505, 232, 189, 141, 30429, 30413, 31124, 30214, 30613, 30899, 30505, 31032, 234, 156, 133, 30446, 232, 136, 149, 235, 133, 168, 235, 134, 153, 31117, 31069, 30847, 30801, 232, 176, 172, 30319, 30993, 233, 182, 132, 232, 157, 183, 30908, 31238, 30698, 31436, 30974, 31475, 236, 137, 174, 30963, 30505, 236, 137, 174, 30486, 30210, 31084, 232, 179, 145, 30557, 234, 184, 169, 232, 176, 172, 30319, 31032, 234, 156, 133, 30267, 2]
inputs:
You are a helpful AI assistant built by NCHC. The user you are helping speaks Traditional Chinese and comes from Taiwan.
 Human: 小兒肥胖超重該如何治療
女寶寶，剛7歲，這一年，察覺到，我家孩子身上肉很多，而且，食量非常的大，平時都不喜歡吃去玩，請問：小兒肥胖超重該如何治療。
Assistant:  孩子出現肥胖症的情況。家長要透過孩子運功和健康的飲食來緩解他的症狀，可以先讓他做一些有氧運動，比如慢跑，爬坡，游泳等，並且飲食上孩子多吃黃瓜，胡蘿蔔，菠菜等，禁止孩子吃一些油炸食品和乾果類食物，這些都是乾熱量高脂肪的食物，而且不要讓孩子總是吃完就躺在床上不動，家長在治療小兒肥胖期間如果孩子情況嚴重就要及時去醫院在醫生的指導下給孩子治療。</s>
label_ids:
[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 29871, 232, 176, 172, 30319, 30544, 31928, 235, 133, 168, 235, 134, 153, 234, 154, 138, 30210, 30993, 233, 182, 132, 30267, 30613, 30899, 30698, 236, 131, 146, 236, 132, 145, 232, 176, 172, 30319, 236, 132, 142, 31134, 30503, 31863, 31577, 30210, 236, 166, 181, 31855, 231, 193, 137, 234, 186, 172, 31201, 31221, 30210, 234, 154, 138, 234, 142, 131, 30214, 30682, 30651, 31244, 235, 177, 150, 31221, 232, 132, 157, 30287, 31959, 30417, 233, 179, 170, 236, 132, 142, 31124, 30214, 31419, 30847, 233, 136, 165, 235, 186, 148, 30214, 234, 139, 175, 232, 160, 164, 30214, 233, 187, 187, 233, 182, 182, 31184, 30214, 231, 187, 169, 231, 187, 151, 236, 166, 181, 31855, 30429, 232, 176, 172, 30319, 30923, 232, 147, 134, 31995, 234, 150, 159, 30214, 235, 134, 164, 235, 155, 194, 235, 151, 151, 30214, 235, 146, 163, 31854, 31184, 30214, 234, 169, 132, 31981, 232, 176, 172, 30319, 232, 147, 134, 30287, 31959, 233, 181, 188, 234, 133, 187, 31855, 31399, 30503, 231, 188, 193, 30801, 236, 164, 161, 31855, 30834, 30214, 236, 131, 156, 31959, 30769, 30392, 231, 188, 193, 234, 137, 180, 31180, 30528, 235, 135, 133, 235, 133, 173, 30210, 31855, 30834, 30214, 31325, 231, 187, 151, 30413, 30698, 235, 177, 150, 232, 176, 172, 30319, 234, 187, 192, 30392, 232, 147, 134, 31366, 31238, 235, 189, 189, 30505, 232, 189, 141, 30429, 30413, 31124, 30214, 30613, 30899, 30505, 31032, 234, 156, 133, 30446, 232, 136, 149, 235, 133, 168, 235, 134, 153, 31117, 31069, 30847, 30801, 232, 176, 172, 30319, 30993, 233, 182, 132, 232, 157, 183, 30908, 31238, 30698, 31436, 30974, 31475, 236, 137, 174, 30963, 30505, 236, 137, 174, 30486, 30210, 31084, 232, 179, 145, 30557, 234, 184, 169, 232, 176, 172, 30319, 31032, 234, 156, 133, 30267, 2]
labels:
孩子出現肥胖症的情況。家長要透過孩子運功和健康的飲食來緩解他的症狀，可以先讓他做一些有氧運動，比如慢跑，爬坡，游泳等，並且飲食上孩子多吃黃瓜，胡蘿蔔，菠菜等，禁止孩子吃一些油炸食品和乾果類食物，這些都是乾熱量高脂肪的食物，而且不要讓孩子總是吃完就躺在床上不動，家長在治療小兒肥胖期間如果孩子情況嚴重就要及時去醫院在醫生的指導下給孩子治療。</s>
04/07/2024 19:28:47 - INFO - llmtuner.model.patcher - Quantizing model to 4 bit.
04/07/2024 19:29:06 - INFO - llmtuner.model.patcher - Gradient checkpointing enabled.
04/07/2024 19:29:06 - INFO - llmtuner.model.adapter - Fine-tuning method: LoRA
04/07/2024 19:29:06 - INFO - llmtuner.model.loader - trainable params: 4194304 || all params: 6742609920 || trainable%: 0.0622
{'loss': 1.538, 'grad_norm': 0.2927384078502655, 'learning_rate': 4.989080197352834e-05, 'epoch': 0.09}
{'loss': 1.4459, 'grad_norm': 0.35563382506370544, 'learning_rate': 4.956416183083221e-05, 'epoch': 0.18}
{'loss': 1.3471, 'grad_norm': 0.4358114004135132, 'learning_rate': 4.9022933048627496e-05, 'epoch': 0.27}
{'loss': 1.2688, 'grad_norm': 0.44441092014312744, 'learning_rate': 4.827184371610511e-05, 'epoch': 0.36}
{'loss': 1.174, 'grad_norm': 0.5329075455665588, 'learning_rate': 4.731745523109029e-05, 'epoch': 0.44}
{'loss': 1.0274, 'grad_norm': 0.6820428371429443, 'learning_rate': 4.6168104980707107e-05, 'epoch': 0.53}
{'loss': 0.8932, 'grad_norm': 0.7699924111366272, 'learning_rate': 4.4833833507280884e-05, 'epoch': 0.62}
{'loss': 0.8837, 'grad_norm': 0.7978638410568237, 'learning_rate': 4.332629679574566e-05, 'epoch': 0.71}
{'loss': 0.7956, 'grad_norm': 0.972001850605011, 'learning_rate': 4.16586644488001e-05, 'epoch': 0.8}
{'loss': 0.6886, 'grad_norm': 1.1022593975067139, 'learning_rate': 3.9845504639337535e-05, 'epoch': 0.89}
{'eval_loss': 0.6431088447570801, 'eval_runtime': 25.4608, 'eval_samples_per_second': 3.928, 'eval_steps_per_second': 3.928, 'epoch': 0.89}
{'loss': 0.6391, 'grad_norm': 1.1113420724868774, 'learning_rate': 3.790265684518767e-05, 'epoch': 0.98}
{'loss': 0.609, 'grad_norm': 1.378251552581787, 'learning_rate': 3.5847093477938956e-05, 'epoch': 1.07}
{'loss': 0.5303, 'grad_norm': 1.3891805410385132, 'learning_rate': 3.369677161463068e-05, 'epoch': 1.16}
{'loss': 0.5149, 'grad_norm': 1.1685264110565186, 'learning_rate': 3.147047612756302e-05, 'epoch': 1.24}
{'loss': 0.4132, 'grad_norm': 1.3068269491195679, 'learning_rate': 2.918765558261841e-05, 'epoch': 1.33}
{'loss': 0.4421, 'grad_norm': 1.2386083602905273, 'learning_rate': 2.686825233966061e-05, 'epoch': 1.42}
{'loss': 0.4174, 'grad_norm': 1.5922112464904785, 'learning_rate': 2.4532528339227452e-05, 'epoch': 1.51}
{'loss': 0.3594, 'grad_norm': 1.2540106773376465, 'learning_rate': 2.2200888097417307e-05, 'epoch': 1.6}
{'loss': 0.3492, 'grad_norm': 1.3953112363815308, 'learning_rate': 1.9893700455257996e-05, 'epoch': 1.69}
{'loss': 0.3109, 'grad_norm': 1.4894928932189941, 'learning_rate': 1.7631120639727393e-05, 'epoch': 1.78}
{'eval_loss': 0.3210313022136688, 'eval_runtime': 25.6969, 'eval_samples_per_second': 3.892, 'eval_steps_per_second': 3.892, 'epoch': 1.78}
{'loss': 0.3752, 'grad_norm': 1.3387280702590942, 'learning_rate': 1.5432914190872757e-05, 'epoch': 1.87}
{'loss': 0.3347, 'grad_norm': 1.2255138158798218, 'learning_rate': 1.331828429317345e-05, 'epoch': 1.96}
{'loss': 0.2721, 'grad_norm': 1.2638672590255737, 'learning_rate': 1.130570401955322e-05, 'epoch': 2.04}
{'loss': 0.3418, 'grad_norm': 1.7724158763885498, 'learning_rate': 9.412754953531663e-06, 'epoch': 2.13}
{'loss': 0.3698, 'grad_norm': 1.268503189086914, 'learning_rate': 7.65597359928646e-06, 'epoch': 2.22}
{'loss': 0.3523, 'grad_norm': 1.3270355463027954, 'learning_rate': 6.050706921363672e-06, 'epoch': 2.31}
{'loss': 0.3095, 'grad_norm': 1.2333977222442627, 'learning_rate': 4.610978276018496e-06, 'epoch': 2.4}
{'loss': 0.3289, 'grad_norm': 1.1552785634994507, 'learning_rate': 3.3493649053890326e-06, 'epoch': 2.49}
{'loss': 0.2321, 'grad_norm': 1.3201309442520142, 'learning_rate': 2.2768880646947268e-06, 'epoch': 2.58}
{'loss': 0.2384, 'grad_norm': 1.2683935165405273, 'learning_rate': 1.4029167422908107e-06, 'epoch': 2.67}
{'eval_loss': 0.27507176995277405, 'eval_runtime': 24.9231, 'eval_samples_per_second': 4.012, 'eval_steps_per_second': 4.012, 'epoch': 2.67}
{'loss': 0.2551, 'grad_norm': 1.1556106805801392, 'learning_rate': 7.350858136652261e-07, 'epoch': 2.76}
{'loss': 0.2846, 'grad_norm': 1.2734512090682983, 'learning_rate': 2.7922934437178695e-07, 'epoch': 2.84}
{'loss': 0.3163, 'grad_norm': 1.3397729396820068, 'learning_rate': 3.9329624554584884e-08, 'epoch': 2.93}
{'train_runtime': 1644.4675, 'train_samples_per_second': 1.642, 'train_steps_per_second': 0.204, 'train_loss': 0.5893653797961417, 'epoch': 2.99}
***** train metrics *****
  epoch                    =       2.99
  train_loss               =     0.5894
  train_runtime            = 0:27:24.46
  train_samples_per_second =      1.642
  train_steps_per_second   =      0.204
Figure saved at: ../../saves/LLaMA2-7B/lora/02_sft/training_loss.png
Figure saved at: ../../saves/LLaMA2-7B/lora/02_sft/training_eval_loss.png
***** eval metrics *****
  epoch                   =       2.99
  eval_loss               =     0.2751
  eval_runtime            = 0:00:24.47
  eval_samples_per_second =      4.085
  eval_steps_per_second   =      4.085
